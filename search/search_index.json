{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Medical-AI is an AI framework for rapid prototyping/experimentation of AI for Medical Applications Documentation : https://aibharata.github.io/medicalAI/ Source Code : https://github.com/aibharata/medicalai Youtube Tutorial : Medical-AI is an AI framework for rapid prototyping of AI for Medical Applications. Installation \u00b6 $ pip install medicalai ---> 100% Requirements \u00b6 Python Version : 3.5-3.7 (Doesn't Work on 3.8 Since Tensorflow does not support 3.8 yet. Dependencies: Numpy, Tensorflow, Seaborn, Matplotlib, Pandas NOTE: Dependency libraries are automatically installed. No need for user to install them manually. Usage \u00b6 Getting Started Tutorial: Google Colab \u00b6 Google Colab Notebook Link Importing the Library \u00b6 import medicalai as ai Using Templates \u00b6 You can use the following templates to perform specific Tasks Load Dataset From Folder \u00b6 Set the path of the dataset and set the target dimension of image that will be input to AI network. trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( 96 , 96 )) . load_dataset () - trainSet contains 'data' and 'labels' accessible by trainSet.data and trainSet.labels - testSet contains 'data' and 'labels' accessible by testSet.data and testSet.labels - labelNames contains class names/labels Check Loaded Dataset Size \u00b6 print ( trainSet . data . shape ) print ( trainSet . labels . shape ) Run Training and Save Model \u00b6 trainer = ai . TRAIN_ENGINE () trainer . train_and_save_model ( AI_NAME = 'tinyMedNet' , MODEL_SAVE_NAME = 'PATH_WHERE_MODEL_IS_SAVED_TO' , trainSet , testSet , OUTPUT_CLASSES , RETRAIN_MODEL = True , BATCH_SIZE = 32 , EPOCHS = 10 , LEARNING_RATE = 0.001 ) Plot Training Loss and Accuracy \u00b6 trainer . plot_train_acc_loss () Generate a comprehensive evaluation PDF report \u00b6 trainer . generate_evaluation_report () PDF report will be generated with model sensitivity, specificity, accuracy, confidence intervals, ROC Curve Plot, Precision Recall Curve Plot, and Confusion Matrix Plot for each class. This function can be used when evaluating a model with Test or Validation Data Set. Explain the Model on a sample \u00b6 trainer . explain ( testSet . data [ 0 : 1 ], layer_to_explain = 'CNN3' ) Loading Model for Prediction \u00b6 infEngine = ai . INFERENCE_ENGINE ( modelName = 'PATH_WHERE_MODEL_IS_SAVED_TO' ) Predict With Labels \u00b6 infEngine . predict_with_labels ( testSet . data [ 0 : 2 ], top_preds = 3 ) Get Just Values of Prediction without postprocessing \u00b6 infEngine . predict ( testSet . data [ 0 : 2 ]) Alternatively, use a faster prediction method in production \u00b6 infEngine . predict_pipeline ( testSet . data [ 0 : 1 ]) Advanced Usage \u00b6 Code snippet for Training Using Medical-AI \u00b6 ## Setup AI Model Manager with required AI. model = ai . modelManager ( AI_NAME = AI_NAME , modelName = MODEL_SAVE_NAME , x_train = train_data , OUTPUT_CLASSES = OUTPUT_CLASSES , RETRAIN_MODEL = RETRAIN_MODEL ) # Start Training result = ai . train ( model , train_data , train_labels , BATCH_SIZE , EPOCHS , LEARNING_RATE , validation_data = ( test_data , test_labels ), callbacks = [ 'tensorboard' ]) # Evaluate Trained Model on Test Data model . evaluate ( test_data , test_labels ) # Plot Accuracy vs Loss for Training ai . plot_training_metrics ( result ) #Save the Trained Model ai . save_model_and_weights ( model , outputName = MODEL_SAVE_NAME ) Automated Tests \u00b6 To Check the tests pytest To See Output of Print Statements pytest -s","title":"Home"},{"location":"#installation","text":"$ pip install medicalai ---> 100%","title":"Installation"},{"location":"#requirements","text":"Python Version : 3.5-3.7 (Doesn't Work on 3.8 Since Tensorflow does not support 3.8 yet. Dependencies: Numpy, Tensorflow, Seaborn, Matplotlib, Pandas NOTE: Dependency libraries are automatically installed. No need for user to install them manually.","title":"Requirements"},{"location":"#usage","text":"","title":"Usage"},{"location":"#getting-started-tutorial-google-colab","text":"Google Colab Notebook Link","title":"Getting Started Tutorial: Google Colab"},{"location":"#importing-the-library","text":"import medicalai as ai","title":"Importing the Library"},{"location":"#using-templates","text":"You can use the following templates to perform specific Tasks","title":"Using Templates"},{"location":"#load-dataset-from-folder","text":"Set the path of the dataset and set the target dimension of image that will be input to AI network. trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( 96 , 96 )) . load_dataset () - trainSet contains 'data' and 'labels' accessible by trainSet.data and trainSet.labels - testSet contains 'data' and 'labels' accessible by testSet.data and testSet.labels - labelNames contains class names/labels","title":"Load Dataset From Folder"},{"location":"#check-loaded-dataset-size","text":"print ( trainSet . data . shape ) print ( trainSet . labels . shape )","title":"Check Loaded Dataset Size"},{"location":"#run-training-and-save-model","text":"trainer = ai . TRAIN_ENGINE () trainer . train_and_save_model ( AI_NAME = 'tinyMedNet' , MODEL_SAVE_NAME = 'PATH_WHERE_MODEL_IS_SAVED_TO' , trainSet , testSet , OUTPUT_CLASSES , RETRAIN_MODEL = True , BATCH_SIZE = 32 , EPOCHS = 10 , LEARNING_RATE = 0.001 )","title":"Run Training and Save Model"},{"location":"#plot-training-loss-and-accuracy","text":"trainer . plot_train_acc_loss ()","title":"Plot Training Loss and Accuracy"},{"location":"#generate-a-comprehensive-evaluation-pdf-report","text":"trainer . generate_evaluation_report () PDF report will be generated with model sensitivity, specificity, accuracy, confidence intervals, ROC Curve Plot, Precision Recall Curve Plot, and Confusion Matrix Plot for each class. This function can be used when evaluating a model with Test or Validation Data Set.","title":"Generate a comprehensive evaluation PDF report"},{"location":"#explain-the-model-on-a-sample","text":"trainer . explain ( testSet . data [ 0 : 1 ], layer_to_explain = 'CNN3' )","title":"Explain the Model on a sample"},{"location":"#loading-model-for-prediction","text":"infEngine = ai . INFERENCE_ENGINE ( modelName = 'PATH_WHERE_MODEL_IS_SAVED_TO' )","title":"Loading Model for Prediction"},{"location":"#predict-with-labels","text":"infEngine . predict_with_labels ( testSet . data [ 0 : 2 ], top_preds = 3 )","title":"Predict With Labels"},{"location":"#get-just-values-of-prediction-without-postprocessing","text":"infEngine . predict ( testSet . data [ 0 : 2 ])","title":"Get Just Values of Prediction without postprocessing"},{"location":"#alternatively-use-a-faster-prediction-method-in-production","text":"infEngine . predict_pipeline ( testSet . data [ 0 : 1 ])","title":"Alternatively, use a faster prediction method in production"},{"location":"#advanced-usage","text":"","title":"Advanced Usage"},{"location":"#code-snippet-for-training-using-medical-ai","text":"## Setup AI Model Manager with required AI. model = ai . modelManager ( AI_NAME = AI_NAME , modelName = MODEL_SAVE_NAME , x_train = train_data , OUTPUT_CLASSES = OUTPUT_CLASSES , RETRAIN_MODEL = RETRAIN_MODEL ) # Start Training result = ai . train ( model , train_data , train_labels , BATCH_SIZE , EPOCHS , LEARNING_RATE , validation_data = ( test_data , test_labels ), callbacks = [ 'tensorboard' ]) # Evaluate Trained Model on Test Data model . evaluate ( test_data , test_labels ) # Plot Accuracy vs Loss for Training ai . plot_training_metrics ( result ) #Save the Trained Model ai . save_model_and_weights ( model , outputName = MODEL_SAVE_NAME )","title":"Code snippet for Training Using Medical-AI"},{"location":"#automated-tests","text":"To Check the tests pytest To See Output of Print Statements pytest -s","title":"Automated Tests"},{"location":"medicalai/core/","text":"medicalai.chief.core \u00b6 create_model_output_folder \u00b6 create_model_output_folder ( outputName ) Creates model output folder if model doesn't exist. Arguments outputName : (Type - filepath ): name of the folder where model needs to be created. Returns None : None check_model_exists \u00b6 check_model_exists ( outputName ) Checks if the given model's network file exists or not. Model name expected is modelName + _arch.json . Arguments outputName : (Type - filepath ): model name to check. Returns Bool : If model network exists returns True else False . save_model_and_weights \u00b6 save_model_and_weights ( model , outputName ) Saves the passed model to MedicalAI Format. Accepts a model and converts to MedicalAI Format. Produces weight file ( outputName + _wgts.h5 ) and network file ( outputName + _arch.json ) IMPORTANT DO NOT PASS ANY EXTENTION TO outputName argument Arguments model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. outputName : (Type - filepath ): model path/name to save. Returns None : None load_model_and_weights \u00b6 load_model_and_weights ( modelName , summary = False ) Loads model from the given filepath. Function Expects weight file ( modelName + _wgts.h5 ) and network file ( modelName + _arch.json ). NOTE DO NOT PASS ANY EXTENTION TO outputName argument For Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' load_model_and_weights ( modelName , summary = False ) load_model_and_weights ( modelName = 'devModel/testmodel1' ) load_model_and_weights ( 'devModel/testmodel1' , summary = True ) Arguments modelName : (Type - filepath ): model path/name to save. summary : (Type - Bool ): Show loaded network architecture and parameter summary. Returns model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. modelManager \u00b6 modelManager ( modelName , x_train , OUTPUT_CLASSES , RETRAIN_MODEL , AI_NAME = 'tinyMedNet' , convLayers = None ) Model manager is used to build new model for given networks/AI or reload existing AI model. This function can be used to retrain existing models or create new models. IMPORTANT DO NOT PASS ANY EXTENTION TO modelName argument Arguments modelName : (Type - filepath ): model path/name to load existing model or create new model. x_train : (Type - numpy.array ): training dataset - expected shape [num_samples*dimension_of_input]. OUTPUT_CLASSES : (Type - Int ): Number of unique classes in dataset. RETRAIN_MODEL : (Type - Bool ): Whether to retrain existing model. If set to True and model does not exist, then it creates a new model and subsequent runs will retrain model. AI_NAME : (Type - String or Custom Network Class ): Select AI Networks from existing catalogue in MedicalAI. See AI_NAME Page for More Details. convLayers : (Type - Int ): [Optional] Default is None. Only applicable for certain networks where convolution layers are reconfigurable. This parameter can be used to change the num of conv layers in Network. See AI_NAME Page for More Details. Returns model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. See Also: TRAIN_ENGINE, INFERENCE_ENGINE show_model_details \u00b6 show_model_details ( model ) Show model network structure and print parameters summary. Arguments model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. Returns None : None; Prints the model summary predict_labels \u00b6 predict_labels ( model , input , expected_output = None , labelNames = None , top_preds = 4 ) predict_labels ( model , input , expected_output = expected_output , labelNames = classNames , top_preds = 4 ) INFERENCE_ENGINE \u00b6 INFERENCE_ENGINE ( self , modelName = None , testSet = None , classNames = None ) Initializes Inference Engine to perform inference/prediction on a trained model. Can be used during production. Arguments modelName : (Type - filepath ): model path/name to load existing model or create new model. testSet : (Type - numpy.array or generator ): [Optional] : Test/Validation Dataset either as generator or numpy array. Only passed if performing evaluation. No need to set this during production. classNames : (Type - list or numpy.array ): [Optional] : classNames or labelNames for the dataset. Returns INFERENCE_ENGINE Object : If modelName is supplied, returns an object with loaded model. load_model_and_weights \u00b6 INFERENCE_ENGINE . load_model_and_weights ( modelName , summary = False ) Loads model from the given filepath. Function Expects path to weight file ( modelName + _wgts.h5 ) and network file ( modelName + _arch.json ). NOTE You can use load_network and load_weights if the model files are in MedicalAI Format. WARNING DO NOT PASS ANY EXTENTION TO outputName argument For Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . load_model_and_weights ( modelName , summary = True ) Arguments modelName : (Type - filepath ): model path/name to load. summary : (Type - Bool ): [Optional] : Default = False . Show loaded network architecture and parameter summary. Returns None : Intializes Object with model. load_network \u00b6 INFERENCE_ENGINE . load_network ( fileName ) Loads network from given filepath. Function Expects path to network file with .json extension. NOTE Use this function only if the model files are not in MedicalAI Format. Example: networkFile = 'devModel/testmodel1.json' infEngine = INFERENCE_ENGINE () infEngine . load_network ( networkFile ) Arguments modelName : (Type - filepath ): model network path/name to load. File should have .json extension. Returns None : Intializes Object with model network initialized. After this model weights can be loaded. load_weights \u00b6 INFERENCE_ENGINE . load_weights ( wgtfileName ) Loads weight from given filepath. Function Expects path to weight file with .h5 extension. NOTE Use this function only if the model files are not in MedicalAI Format. Before calling this function, network needs to loaded using load_network function. Example: networkFile = 'devModel/testmodel1.json' wgtFile = 'devModel/testmodel1.h5' infEngine = INFERENCE_ENGINE () infEngine . load_network ( networkFile ) infEngine . load_weights ( wgtFile ) Arguments wgtfileName : (Type - filepath ): model weight filepath/name to load. File should have .h5 extension. Returns None : Intializes Object with model loaded with weights. preprocessor_from_meta \u00b6 INFERENCE_ENGINE . preprocessor_from_meta ( metaFile = None ) Loads preprocessor parameter and initializes preprocessor from meta file generated by MedicalAI. If the model is trained using this framework, then the metafile is automatically available and initialized. WARNING If model is not trained using this framework, then one can use this engine by creating metafile similar to one generated by this framework. Please see repo for more details. Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) # There is no need to perform this op if model trained using this framework. It is automatically Initialized. # There is no need to pass modelName if the model is trained using framework infEngine . preprocessor_from_meta () infEngine . preprocessor_from_meta ( metaFile = 'myMetaFile.json' ) [ ` Else ` ]( #Else) pass the metafile Arguments metaFile : (Type - filepath ): [Optional] : if no parameter is passed, then it will look for modelname + _meta.json file. If modelname is set during INFERENCE_ENGINE initialization, then it automatically handles this. Returns None : Intializes Object with Preprocessor into process pipeline. predict \u00b6 INFERENCE_ENGINE . predict ( input ) Peform prediction on Input. Input can be Numpy Array or Image or Data Generator (in case of Test/Validation). Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . preprocessor_from_meta () # Predict an input image infEngine . predict ( input = 'test.jpg' ) Arguments input : (Type - numpy.array | imagePath | generator ): Can be single image file or numpy array of multiple images or data generator class. Returns Numpy.Array : of Predictions. Shape of Output [Number of Inputs, Number of Output Classes in Model] predict_pipeline \u00b6 INFERENCE_ENGINE . predict_pipeline ( input ) Slightly Faster version of predict. Useful for deployment. Do not use INFERENCE_ENGINE.predict in production. Peform prediction on Input. Input can be Numpy Array or Image or Data Generator (in case of Test/Validation). Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . preprocessor_from_meta () # Predict an input image infEngine . predict_pipeline ( input = 'test.jpg' ) Arguments input : (Type - numpy.array | imagePath | generator ): Can be single image file or numpy array of multiple images or data generator class. Returns Numpy.Array : of Predictions. Shape of Output [Number of Inputs, Number of Output Classes in Model] decode_predictions \u00b6 INFERENCE_ENGINE . decode_predictions ( pred , top_preds = 4 , retType = 'tuple' ) Returns Decodes predictions with label/class names with output probabilites. During production this can be used to return a json serializable dictionary instead of tuple. Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . preprocessor_from_meta () # Predict an input image pred = infEngine . predict_pipeline ( input = 'test.jpg' ) pred_tuple = infEngine . decode_predictions ( pred , top_preds = 2 ) # Get a json serializable dictionary instead of tuple pred_dict = infEngine . decode_predictions ( pred , top_preds = 2 , retType = 'dict' ) Arguments pred : (Type - numpy.array ): Prediction output of either INFERENCE_ENGINE.predict or INFERENCE_ENGINE.predict_pipleline . top_preds : (Type - Integer ): [Optional] : Default = 4 - Number of top prediction to return. If the number is set to higher than number of classes in network, it returns all predictions. retType : (Type - String ): [Optional] : Default = tuple . Options - [ dict or tuple ]. Dict helpful in production. Returns Tuple or Dict : of Predictions with probabilities. Shape of Output [Number of Inputs, Max(top_preds,Number of Output Classes in Model)] getLayerNames \u00b6 INFERENCE_ENGINE . getLayerNames () Get the layer names of the network. Useful for when using Explainable-AI function as it expects layer name as argument. Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) # Print the Layer Names print ( ' '.join(infEngine.getLayerNames())) summary \u00b6 INFERENCE_ENGINE . summary () Show model network structure and print parameters summary. Arguments None : None Returns None : None; Prints the model summary generate_evaluation_report \u00b6 INFERENCE_ENGINE . generate_evaluation_report ( testSet = None , predictions = None , printStat = False , returnPlot = False , showPlot = False , pdfName = None , ** kwargs ) Generate a comprehensive PDF report with model sensitivity, specificity, accuracy, confidence intervals, ROC Curve Plot, Precision Recall Curve Plot, and Confusion Matrix Plot for each class. This function can be used when evaluating a model with Test or Validation Data Set. Example: # Load Dataset trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( 224 , 224 )) . load_dataset () # Intialize Inference Engine infEngine = ai . INFERENCE_ENGINE ( MODEL_SAVE_NAME ) # Preform Prediction on DataSet predsG = infEngine . predict ( testSet . data ) # Generate Report infEngine . generate_evaluation_report ( testSet , predictions = predsG , pdfName = \"expt_evaluation_report.pdf\" ) Alternatively: # Load Dataset trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( 224 , 224 )) . load_dataset () # Intialize Inference Engine infEngine = ai . INFERENCE_ENGINE ( MODEL_SAVE_NAME ) # Generate Report - If predictions are not passed, then automatically prediction is performed. infEngine . generate_evaluation_report ( testSet , pdfName = \"expt_evaluation_report.pdf\" ) Arguments testSet : (Type - numpy.array or generator ) : Test Data Set to perform evaluation on. predictions : (Type - numpy.array ): [Optional] : Prediction output of either INFERENCE_ENGINE.predict or INFERENCE_ENGINE.predict_pipleline . If this parameter is not set, then prediction is perfomred internally and evaluation report is generated. pdfName : (Type - Bool ): [Optional] : Default = ModelName + _report.pdf - Pdf Output Name. printStat : (Type - Bool ): [Optional] : Default = False - Print Statistics on console. returnPlot : (Type - Bool ): [Optional] : Default = False - Return Plot Figure Handle. showPlot : (Type - Bool ): [Optional] : Default = False - Show Plot figure. Returns None or Plot Handle : If returnPlot = True then Plot Handle will be returned else None. explain \u00b6 INFERENCE_ENGINE . explain ( input , predictions = None , layer_to_explain = 'CNN3' , classNames = None , selectedClasses = None , expectedClass = None , showPlot = False ) Explains a model layer with respect to Input and Output using Grad-cam. Basically, see what the AI is seeing to arrive at a certain prediction. More methods to be updated in next versions. # Load a sample image = load ( Image ) # Intialize Inference Engine infEngine = ai . INFERENCE_ENGINE ( MODEL_SAVE_NAME ) # Print Layer Names print ( ' '.join(infEngine.getLayerNames())) # If predictions are not passed, then automatically prediction is performed. You can perform prediction first then pass to the below function . Pass one of the layer name from above output to ` layer_to_explain ` . infEngine . explain ( image , layer_to_explain = 'CNN3' ) Arguments input : (Type - numpy.array or image ) : Input to perform explanation on. For safety, pass single or few samples only. predictions : (Type - numpy.array ): [Optional] : Prediction output of either INFERENCE_ENGINE.predict or INFERENCE_ENGINE.predict_pipleline . If this parameter is not set, then prediction is perfomred internally and explanation is generated. layer_to_explain : (Type - String ): Layer to explain. classNames : (Type - Numpy.Array or List ): [Optional] : Default = None| Loaded from Meta File - Class Names or Label Names of Dataset. selectedClasses : (Type - Bool ): [Optional] : Default = None - Explain only few subset of Class Names. If None then all classes will be explained. expectedClass : (Type - Bool ): [Optional] : Default = None - Expected Label/Class Name for the Input. Returns None : Shows a plot figure with explanations. TRAIN_ENGINE \u00b6 TRAIN_ENGINE ( self , modelName = None ) Initializes Training Engine to perform training/prediction. TRAIN_ENGINE is a superclass of INFERENCE_ENGINE. Meaning, all the methods and functions of INFERENCE_ENGINE are available with TRAIN_ENGINE with additional methods of its own. Arguments modelName : (Type - filepath ): [Optional] model path/name to load existing model or create new model. Returns TRAIN_ENGINE Object : Ready to Train a given dataset. train_and_save_model \u00b6 TRAIN_ENGINE . train_and_save_model ( AI_NAME , MODEL_SAVE_NAME , trainSet , testSet , OUTPUT_CLASSES , RETRAIN_MODEL , BATCH_SIZE , EPOCHS , LEARNING_RATE , convLayers = None , SAVE_BEST_MODEL = False , BEST_MODEL_COND = None , callbacks = None , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ], showModel = False , CLASS_WEIGHTS = None ) \" Main function that trains and saves a model. This automatically builds new model for given networks/AI or reload existing AI model. This function can be used to retrain existing models or create new models. IMPORTANT DO NOT PASS ANY EXTENTION TO MODEL_SAVE_NAME argument USAGE: # Set Parameters AI_NAME = 'MobileNet_X' MODEL_SAVE_NAME = 'testModel1' OUTPUT_CLASSES = 10 RETRAIN_MODEL = True EPOCHS = 10 BATCH_SIZE = 32 LEARNING_RATE = 0.0001 SAVE_BEST_MODEL = False BEST_MODEL_COND = None callbacks = None # Initialize Train Engine trainer = ai . TRAIN_ENGINE () # Train and Save Model trainer . train_and_save_model ( AI_NAME = AI_NAME , # AI/Network to Use MODEL_SAVE_NAME = MODEL_SAVE_NAME , # Target MODEL To Save/Load/Retrain trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , # From Dataset Loader RETRAIN_MODEL = RETRAIN_MODEL , BATCH_SIZE = BATCH_SIZE , EPOCHS = EPOCHS , # Training Settings SAVE_BEST_MODEL = SAVE_BEST_MODEL , BEST_MODEL_COND = BEST_MODEL_COND , # Early Stopping Settings loss = 'categorical_crossentropy' , # Loss Function showModel = False , # Show Network Summary callbacks = callbacks , # Additional/Advanced Hooks ) Arguments AI_NAME : (Type - string or NetworkInit() class ): Select Network from catalogue (string) or create your own network and pass the class. MODEL_SAVE_NAME : (Type - filepath ): [Optional] model path/name to load existing model or create new model. trainSet : (Type - numpy.array or generator ): [Optional] : Training Dataset either as generator or numpy array from DataLoader class. testSet : (Type - numpy.array or generator ): [Optional] : Test/Validation Dataset either as generator or numpy array from DataLoader class. OUTPUT_CLASSES : (Type - Int ): Number of unique classes in dataset. RETRAIN_MODEL : (Type - Bool ): Whether to retrain existing model. If set to True and model does not exist, then it creates a new model and subsequent runs will retrain model. BATCH_SIZE : (Type - Int ): Batch size for Training. If Training fails when using large datasets, try reducing this number. EPOCHS : (Type - Int ): Number of Epochs to train. LEARNING_RATE : (Type - Float ): [Optional] : Set Learning rate. If not set, optimizer default will be used. convLayers : (Type - Int ): [Optional] Default is None. Only applicable for certain networks where convolution layers are reconfigurable. This parameter can be used to change the num of conv layers in Network. See AI_NAME Page for More Details. SAVE_BEST_MODEL : (Type - Bool ): [Optional] : Default: False - Initializes Training Engine with saving best model feature. BEST_MODEL_COND : (Type - String or Dict ): [Optional] : Default: None - Initializes Training Engine with early stopping feature. [Options] -> Default or Dict . Dict Values Expected : 'monitor' : (Type - String ): Which Parameter to Monitor. [Options] -> ('val_accuracy', 'val_loss', 'accuracy'), 'min_delta' : (Type - Float ): minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. 'patience' : (Type - Int ): number of epochs with no improvement after which training will be stopped. loss : (Type - String ) : Default: sparse_categorical_crossentropy , Loss function to apply. Depends on dataprocessor. If dataloaders has one-hot encoded labels then use sparse_categorical_crossentropy else if labers are encoded then -> categorical_crossentropy . metrics : (Type - List ): [Optional] : Default: ['accuracy'] . Metrics to Monitor during Training. showModel : (Type - Bool ): [Optional] : Whether to show the network summary before start of training. CLASS_WEIGHTS : (Type - Dict ) [Optional] : Dictionary containing class weights for model.fit() callbacks : (Type - Tensorflow Callbacks ): Tensorflow Callbacks can be attacked. Returns None : On successful completion saves the trained model. plot_train_acc_loss \u00b6 TRAIN_ENGINE . plot_train_acc_loss () Plot training accuracy and loss graph vs epoch. Generates an interactive graph for inspection. USAGE: # Set Parameters AI_NAME = 'MobileNet_X' MODEL_SAVE_NAME = 'testModel1' OUTPUT_CLASSES = 10 RETRAIN_MODEL = True EPOCHS = 10 BATCH_SIZE = 32 LEARNING_RATE = 0.0001 SAVE_BEST_MODEL = False BEST_MODEL_COND = None callbacks = None # Initialize Train Engine trainer = ai . TRAIN_ENGINE () # Train and Save Model trainer . train_and_save_model ( AI_NAME = AI_NAME , # AI/Network to Use MODEL_SAVE_NAME = MODEL_SAVE_NAME , # Target MODEL To Save/Load/Retrain trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , # From Dataset Loader RETRAIN_MODEL = RETRAIN_MODEL , BATCH_SIZE = BATCH_SIZE , EPOCHS = EPOCHS , # Training Settings SAVE_BEST_MODEL = SAVE_BEST_MODEL , BEST_MODEL_COND = BEST_MODEL_COND , # Early Stopping Settings loss = 'categorical_crossentropy' , # Loss Function showModel = False , # Show Network Summary callbacks = callbacks , # Additional/Advanced Hooks ) trainer . plot_training_metrics () Arguments None : None Returns None : Opens accuracy vs loss vs epoch plot.","title":"Core"},{"location":"medicalai/core/#medicalaichiefcore","text":"","title":"medicalai.chief.core"},{"location":"medicalai/core/#create_model_output_folder","text":"create_model_output_folder ( outputName ) Creates model output folder if model doesn't exist. Arguments outputName : (Type - filepath ): name of the folder where model needs to be created. Returns None : None","title":"create_model_output_folder"},{"location":"medicalai/core/#check_model_exists","text":"check_model_exists ( outputName ) Checks if the given model's network file exists or not. Model name expected is modelName + _arch.json . Arguments outputName : (Type - filepath ): model name to check. Returns Bool : If model network exists returns True else False .","title":"check_model_exists"},{"location":"medicalai/core/#save_model_and_weights","text":"save_model_and_weights ( model , outputName ) Saves the passed model to MedicalAI Format. Accepts a model and converts to MedicalAI Format. Produces weight file ( outputName + _wgts.h5 ) and network file ( outputName + _arch.json ) IMPORTANT DO NOT PASS ANY EXTENTION TO outputName argument Arguments model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. outputName : (Type - filepath ): model path/name to save. Returns None : None","title":"save_model_and_weights"},{"location":"medicalai/core/#load_model_and_weights","text":"load_model_and_weights ( modelName , summary = False ) Loads model from the given filepath. Function Expects weight file ( modelName + _wgts.h5 ) and network file ( modelName + _arch.json ). NOTE DO NOT PASS ANY EXTENTION TO outputName argument For Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' load_model_and_weights ( modelName , summary = False ) load_model_and_weights ( modelName = 'devModel/testmodel1' ) load_model_and_weights ( 'devModel/testmodel1' , summary = True ) Arguments modelName : (Type - filepath ): model path/name to save. summary : (Type - Bool ): Show loaded network architecture and parameter summary. Returns model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class.","title":"load_model_and_weights"},{"location":"medicalai/core/#modelmanager","text":"modelManager ( modelName , x_train , OUTPUT_CLASSES , RETRAIN_MODEL , AI_NAME = 'tinyMedNet' , convLayers = None ) Model manager is used to build new model for given networks/AI or reload existing AI model. This function can be used to retrain existing models or create new models. IMPORTANT DO NOT PASS ANY EXTENTION TO modelName argument Arguments modelName : (Type - filepath ): model path/name to load existing model or create new model. x_train : (Type - numpy.array ): training dataset - expected shape [num_samples*dimension_of_input]. OUTPUT_CLASSES : (Type - Int ): Number of unique classes in dataset. RETRAIN_MODEL : (Type - Bool ): Whether to retrain existing model. If set to True and model does not exist, then it creates a new model and subsequent runs will retrain model. AI_NAME : (Type - String or Custom Network Class ): Select AI Networks from existing catalogue in MedicalAI. See AI_NAME Page for More Details. convLayers : (Type - Int ): [Optional] Default is None. Only applicable for certain networks where convolution layers are reconfigurable. This parameter can be used to change the num of conv layers in Network. See AI_NAME Page for More Details. Returns model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. See Also: TRAIN_ENGINE, INFERENCE_ENGINE","title":"modelManager"},{"location":"medicalai/core/#show_model_details","text":"show_model_details ( model ) Show model network structure and print parameters summary. Arguments model : (Type - model class): MedicalAI/Keras/Tensorflow 2.0+ model class. Returns None : None; Prints the model summary","title":"show_model_details"},{"location":"medicalai/core/#predict_labels","text":"predict_labels ( model , input , expected_output = None , labelNames = None , top_preds = 4 ) predict_labels ( model , input , expected_output = expected_output , labelNames = classNames , top_preds = 4 )","title":"predict_labels"},{"location":"medicalai/core/#inference_engine","text":"INFERENCE_ENGINE ( self , modelName = None , testSet = None , classNames = None ) Initializes Inference Engine to perform inference/prediction on a trained model. Can be used during production. Arguments modelName : (Type - filepath ): model path/name to load existing model or create new model. testSet : (Type - numpy.array or generator ): [Optional] : Test/Validation Dataset either as generator or numpy array. Only passed if performing evaluation. No need to set this during production. classNames : (Type - list or numpy.array ): [Optional] : classNames or labelNames for the dataset. Returns INFERENCE_ENGINE Object : If modelName is supplied, returns an object with loaded model.","title":"INFERENCE_ENGINE"},{"location":"medicalai/core/#load_model_and_weights_1","text":"INFERENCE_ENGINE . load_model_and_weights ( modelName , summary = False ) Loads model from the given filepath. Function Expects path to weight file ( modelName + _wgts.h5 ) and network file ( modelName + _arch.json ). NOTE You can use load_network and load_weights if the model files are in MedicalAI Format. WARNING DO NOT PASS ANY EXTENTION TO outputName argument For Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . load_model_and_weights ( modelName , summary = True ) Arguments modelName : (Type - filepath ): model path/name to load. summary : (Type - Bool ): [Optional] : Default = False . Show loaded network architecture and parameter summary. Returns None : Intializes Object with model.","title":"load_model_and_weights"},{"location":"medicalai/core/#load_network","text":"INFERENCE_ENGINE . load_network ( fileName ) Loads network from given filepath. Function Expects path to network file with .json extension. NOTE Use this function only if the model files are not in MedicalAI Format. Example: networkFile = 'devModel/testmodel1.json' infEngine = INFERENCE_ENGINE () infEngine . load_network ( networkFile ) Arguments modelName : (Type - filepath ): model network path/name to load. File should have .json extension. Returns None : Intializes Object with model network initialized. After this model weights can be loaded.","title":"load_network"},{"location":"medicalai/core/#load_weights","text":"INFERENCE_ENGINE . load_weights ( wgtfileName ) Loads weight from given filepath. Function Expects path to weight file with .h5 extension. NOTE Use this function only if the model files are not in MedicalAI Format. Before calling this function, network needs to loaded using load_network function. Example: networkFile = 'devModel/testmodel1.json' wgtFile = 'devModel/testmodel1.h5' infEngine = INFERENCE_ENGINE () infEngine . load_network ( networkFile ) infEngine . load_weights ( wgtFile ) Arguments wgtfileName : (Type - filepath ): model weight filepath/name to load. File should have .h5 extension. Returns None : Intializes Object with model loaded with weights.","title":"load_weights"},{"location":"medicalai/core/#preprocessor_from_meta","text":"INFERENCE_ENGINE . preprocessor_from_meta ( metaFile = None ) Loads preprocessor parameter and initializes preprocessor from meta file generated by MedicalAI. If the model is trained using this framework, then the metafile is automatically available and initialized. WARNING If model is not trained using this framework, then one can use this engine by creating metafile similar to one generated by this framework. Please see repo for more details. Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) # There is no need to perform this op if model trained using this framework. It is automatically Initialized. # There is no need to pass modelName if the model is trained using framework infEngine . preprocessor_from_meta () infEngine . preprocessor_from_meta ( metaFile = 'myMetaFile.json' ) [ ` Else ` ]( #Else) pass the metafile Arguments metaFile : (Type - filepath ): [Optional] : if no parameter is passed, then it will look for modelname + _meta.json file. If modelname is set during INFERENCE_ENGINE initialization, then it automatically handles this. Returns None : Intializes Object with Preprocessor into process pipeline.","title":"preprocessor_from_meta"},{"location":"medicalai/core/#predict","text":"INFERENCE_ENGINE . predict ( input ) Peform prediction on Input. Input can be Numpy Array or Image or Data Generator (in case of Test/Validation). Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . preprocessor_from_meta () # Predict an input image infEngine . predict ( input = 'test.jpg' ) Arguments input : (Type - numpy.array | imagePath | generator ): Can be single image file or numpy array of multiple images or data generator class. Returns Numpy.Array : of Predictions. Shape of Output [Number of Inputs, Number of Output Classes in Model]","title":"predict"},{"location":"medicalai/core/#predict_pipeline","text":"INFERENCE_ENGINE . predict_pipeline ( input ) Slightly Faster version of predict. Useful for deployment. Do not use INFERENCE_ENGINE.predict in production. Peform prediction on Input. Input can be Numpy Array or Image or Data Generator (in case of Test/Validation). Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . preprocessor_from_meta () # Predict an input image infEngine . predict_pipeline ( input = 'test.jpg' ) Arguments input : (Type - numpy.array | imagePath | generator ): Can be single image file or numpy array of multiple images or data generator class. Returns Numpy.Array : of Predictions. Shape of Output [Number of Inputs, Number of Output Classes in Model]","title":"predict_pipeline"},{"location":"medicalai/core/#decode_predictions","text":"INFERENCE_ENGINE . decode_predictions ( pred , top_preds = 4 , retType = 'tuple' ) Returns Decodes predictions with label/class names with output probabilites. During production this can be used to return a json serializable dictionary instead of tuple. Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) infEngine . preprocessor_from_meta () # Predict an input image pred = infEngine . predict_pipeline ( input = 'test.jpg' ) pred_tuple = infEngine . decode_predictions ( pred , top_preds = 2 ) # Get a json serializable dictionary instead of tuple pred_dict = infEngine . decode_predictions ( pred , top_preds = 2 , retType = 'dict' ) Arguments pred : (Type - numpy.array ): Prediction output of either INFERENCE_ENGINE.predict or INFERENCE_ENGINE.predict_pipleline . top_preds : (Type - Integer ): [Optional] : Default = 4 - Number of top prediction to return. If the number is set to higher than number of classes in network, it returns all predictions. retType : (Type - String ): [Optional] : Default = tuple . Options - [ dict or tuple ]. Dict helpful in production. Returns Tuple or Dict : of Predictions with probabilities. Shape of Output [Number of Inputs, Max(top_preds,Number of Output Classes in Model)]","title":"decode_predictions"},{"location":"medicalai/core/#getlayernames","text":"INFERENCE_ENGINE . getLayerNames () Get the layer names of the network. Useful for when using Explainable-AI function as it expects layer name as argument. Example: # If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json` # Then `modelName=devModel/testmodel1` modelName = 'devModel/testmodel1' infEngine = INFERENCE_ENGINE () infEngine . load_model_and_weights ( modelName ) # Print the Layer Names print ( ' '.join(infEngine.getLayerNames()))","title":"getLayerNames"},{"location":"medicalai/core/#summary","text":"INFERENCE_ENGINE . summary () Show model network structure and print parameters summary. Arguments None : None Returns None : None; Prints the model summary","title":"summary"},{"location":"medicalai/core/#generate_evaluation_report","text":"INFERENCE_ENGINE . generate_evaluation_report ( testSet = None , predictions = None , printStat = False , returnPlot = False , showPlot = False , pdfName = None , ** kwargs ) Generate a comprehensive PDF report with model sensitivity, specificity, accuracy, confidence intervals, ROC Curve Plot, Precision Recall Curve Plot, and Confusion Matrix Plot for each class. This function can be used when evaluating a model with Test or Validation Data Set. Example: # Load Dataset trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( 224 , 224 )) . load_dataset () # Intialize Inference Engine infEngine = ai . INFERENCE_ENGINE ( MODEL_SAVE_NAME ) # Preform Prediction on DataSet predsG = infEngine . predict ( testSet . data ) # Generate Report infEngine . generate_evaluation_report ( testSet , predictions = predsG , pdfName = \"expt_evaluation_report.pdf\" ) Alternatively: # Load Dataset trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( 224 , 224 )) . load_dataset () # Intialize Inference Engine infEngine = ai . INFERENCE_ENGINE ( MODEL_SAVE_NAME ) # Generate Report - If predictions are not passed, then automatically prediction is performed. infEngine . generate_evaluation_report ( testSet , pdfName = \"expt_evaluation_report.pdf\" ) Arguments testSet : (Type - numpy.array or generator ) : Test Data Set to perform evaluation on. predictions : (Type - numpy.array ): [Optional] : Prediction output of either INFERENCE_ENGINE.predict or INFERENCE_ENGINE.predict_pipleline . If this parameter is not set, then prediction is perfomred internally and evaluation report is generated. pdfName : (Type - Bool ): [Optional] : Default = ModelName + _report.pdf - Pdf Output Name. printStat : (Type - Bool ): [Optional] : Default = False - Print Statistics on console. returnPlot : (Type - Bool ): [Optional] : Default = False - Return Plot Figure Handle. showPlot : (Type - Bool ): [Optional] : Default = False - Show Plot figure. Returns None or Plot Handle : If returnPlot = True then Plot Handle will be returned else None.","title":"generate_evaluation_report"},{"location":"medicalai/core/#explain","text":"INFERENCE_ENGINE . explain ( input , predictions = None , layer_to_explain = 'CNN3' , classNames = None , selectedClasses = None , expectedClass = None , showPlot = False ) Explains a model layer with respect to Input and Output using Grad-cam. Basically, see what the AI is seeing to arrive at a certain prediction. More methods to be updated in next versions. # Load a sample image = load ( Image ) # Intialize Inference Engine infEngine = ai . INFERENCE_ENGINE ( MODEL_SAVE_NAME ) # Print Layer Names print ( ' '.join(infEngine.getLayerNames())) # If predictions are not passed, then automatically prediction is performed. You can perform prediction first then pass to the below function . Pass one of the layer name from above output to ` layer_to_explain ` . infEngine . explain ( image , layer_to_explain = 'CNN3' ) Arguments input : (Type - numpy.array or image ) : Input to perform explanation on. For safety, pass single or few samples only. predictions : (Type - numpy.array ): [Optional] : Prediction output of either INFERENCE_ENGINE.predict or INFERENCE_ENGINE.predict_pipleline . If this parameter is not set, then prediction is perfomred internally and explanation is generated. layer_to_explain : (Type - String ): Layer to explain. classNames : (Type - Numpy.Array or List ): [Optional] : Default = None| Loaded from Meta File - Class Names or Label Names of Dataset. selectedClasses : (Type - Bool ): [Optional] : Default = None - Explain only few subset of Class Names. If None then all classes will be explained. expectedClass : (Type - Bool ): [Optional] : Default = None - Expected Label/Class Name for the Input. Returns None : Shows a plot figure with explanations.","title":"explain"},{"location":"medicalai/core/#train_engine","text":"TRAIN_ENGINE ( self , modelName = None ) Initializes Training Engine to perform training/prediction. TRAIN_ENGINE is a superclass of INFERENCE_ENGINE. Meaning, all the methods and functions of INFERENCE_ENGINE are available with TRAIN_ENGINE with additional methods of its own. Arguments modelName : (Type - filepath ): [Optional] model path/name to load existing model or create new model. Returns TRAIN_ENGINE Object : Ready to Train a given dataset.","title":"TRAIN_ENGINE"},{"location":"medicalai/core/#train_and_save_model","text":"TRAIN_ENGINE . train_and_save_model ( AI_NAME , MODEL_SAVE_NAME , trainSet , testSet , OUTPUT_CLASSES , RETRAIN_MODEL , BATCH_SIZE , EPOCHS , LEARNING_RATE , convLayers = None , SAVE_BEST_MODEL = False , BEST_MODEL_COND = None , callbacks = None , loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ], showModel = False , CLASS_WEIGHTS = None ) \" Main function that trains and saves a model. This automatically builds new model for given networks/AI or reload existing AI model. This function can be used to retrain existing models or create new models. IMPORTANT DO NOT PASS ANY EXTENTION TO MODEL_SAVE_NAME argument USAGE: # Set Parameters AI_NAME = 'MobileNet_X' MODEL_SAVE_NAME = 'testModel1' OUTPUT_CLASSES = 10 RETRAIN_MODEL = True EPOCHS = 10 BATCH_SIZE = 32 LEARNING_RATE = 0.0001 SAVE_BEST_MODEL = False BEST_MODEL_COND = None callbacks = None # Initialize Train Engine trainer = ai . TRAIN_ENGINE () # Train and Save Model trainer . train_and_save_model ( AI_NAME = AI_NAME , # AI/Network to Use MODEL_SAVE_NAME = MODEL_SAVE_NAME , # Target MODEL To Save/Load/Retrain trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , # From Dataset Loader RETRAIN_MODEL = RETRAIN_MODEL , BATCH_SIZE = BATCH_SIZE , EPOCHS = EPOCHS , # Training Settings SAVE_BEST_MODEL = SAVE_BEST_MODEL , BEST_MODEL_COND = BEST_MODEL_COND , # Early Stopping Settings loss = 'categorical_crossentropy' , # Loss Function showModel = False , # Show Network Summary callbacks = callbacks , # Additional/Advanced Hooks ) Arguments AI_NAME : (Type - string or NetworkInit() class ): Select Network from catalogue (string) or create your own network and pass the class. MODEL_SAVE_NAME : (Type - filepath ): [Optional] model path/name to load existing model or create new model. trainSet : (Type - numpy.array or generator ): [Optional] : Training Dataset either as generator or numpy array from DataLoader class. testSet : (Type - numpy.array or generator ): [Optional] : Test/Validation Dataset either as generator or numpy array from DataLoader class. OUTPUT_CLASSES : (Type - Int ): Number of unique classes in dataset. RETRAIN_MODEL : (Type - Bool ): Whether to retrain existing model. If set to True and model does not exist, then it creates a new model and subsequent runs will retrain model. BATCH_SIZE : (Type - Int ): Batch size for Training. If Training fails when using large datasets, try reducing this number. EPOCHS : (Type - Int ): Number of Epochs to train. LEARNING_RATE : (Type - Float ): [Optional] : Set Learning rate. If not set, optimizer default will be used. convLayers : (Type - Int ): [Optional] Default is None. Only applicable for certain networks where convolution layers are reconfigurable. This parameter can be used to change the num of conv layers in Network. See AI_NAME Page for More Details. SAVE_BEST_MODEL : (Type - Bool ): [Optional] : Default: False - Initializes Training Engine with saving best model feature. BEST_MODEL_COND : (Type - String or Dict ): [Optional] : Default: None - Initializes Training Engine with early stopping feature. [Options] -> Default or Dict . Dict Values Expected : 'monitor' : (Type - String ): Which Parameter to Monitor. [Options] -> ('val_accuracy', 'val_loss', 'accuracy'), 'min_delta' : (Type - Float ): minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. 'patience' : (Type - Int ): number of epochs with no improvement after which training will be stopped. loss : (Type - String ) : Default: sparse_categorical_crossentropy , Loss function to apply. Depends on dataprocessor. If dataloaders has one-hot encoded labels then use sparse_categorical_crossentropy else if labers are encoded then -> categorical_crossentropy . metrics : (Type - List ): [Optional] : Default: ['accuracy'] . Metrics to Monitor during Training. showModel : (Type - Bool ): [Optional] : Whether to show the network summary before start of training. CLASS_WEIGHTS : (Type - Dict ) [Optional] : Dictionary containing class weights for model.fit() callbacks : (Type - Tensorflow Callbacks ): Tensorflow Callbacks can be attacked. Returns None : On successful completion saves the trained model.","title":"train_and_save_model"},{"location":"medicalai/core/#plot_train_acc_loss","text":"TRAIN_ENGINE . plot_train_acc_loss () Plot training accuracy and loss graph vs epoch. Generates an interactive graph for inspection. USAGE: # Set Parameters AI_NAME = 'MobileNet_X' MODEL_SAVE_NAME = 'testModel1' OUTPUT_CLASSES = 10 RETRAIN_MODEL = True EPOCHS = 10 BATCH_SIZE = 32 LEARNING_RATE = 0.0001 SAVE_BEST_MODEL = False BEST_MODEL_COND = None callbacks = None # Initialize Train Engine trainer = ai . TRAIN_ENGINE () # Train and Save Model trainer . train_and_save_model ( AI_NAME = AI_NAME , # AI/Network to Use MODEL_SAVE_NAME = MODEL_SAVE_NAME , # Target MODEL To Save/Load/Retrain trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , # From Dataset Loader RETRAIN_MODEL = RETRAIN_MODEL , BATCH_SIZE = BATCH_SIZE , EPOCHS = EPOCHS , # Training Settings SAVE_BEST_MODEL = SAVE_BEST_MODEL , BEST_MODEL_COND = BEST_MODEL_COND , # Early Stopping Settings loss = 'categorical_crossentropy' , # Loss Function showModel = False , # Show Network Summary callbacks = callbacks , # Additional/Advanced Hooks ) trainer . plot_training_metrics () Arguments None : None Returns None : Opens accuracy vs loss vs epoch plot.","title":"plot_train_acc_loss"},{"location":"medicalai/dataset_processors/","text":"medicalai.chief.dataset_prepare \u00b6 datasetFromFolder \u00b6 datasetFromFolder ( self , folder , targetDim = ( 31 , 31 ), normalize = False , name = None , useCache = True , forceCleanCache = False ) TODO: Fix samplingMethodName assignment datasetGenFromFolder \u00b6 datasetGenFromFolder ( self , folder , targetDim = ( 224 , 224 ), normalize = False , batch_size = 16 , augmentation = True , color_mode = 'rgb' , class_mode = 'sparse' , shuffle = True , seed = 23 ) Create a dataset generator from dataset present in Folder. The folder should consist of test and train folders and each of the folders should have n classes of folders. Arguments folder : The directory must be set to the path where your n classes of folders are present. targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical , in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input . color_mode : grayscale for black and white or grayscale, rgb for three color channels. batch_size : Number of images to be yielded from the generator per batch. If training fails lower this number. augmentation : : [Optional] : Default = True : Perform augmentation on Dataset shuffle : : [Optional] : Default = True : Shuffle Dataset seed : : [Optional] : Default = 23 : Initialize Random Seed Returns None : Initializes Test and Train Data Generators datasetGenFromDataframe \u00b6 datasetGenFromDataframe ( self , folder , csv_path = '.' , x_col = 'name' , y_col = 'labels' , targetDim = ( 224 , 224 ), normalize = False , batch_size = 16 , augmentation = True , color_mode = 'rgb' , class_mode = 'sparse' , shuffle = True , seed = 17 ) Creates Keras Dataset Generator for Handling Large Datasets from DataFrame. Arguments csv_path : folder containing train.csv and test.csv. folder : The directory must be set to the path where your training images are present. x_col : Name of column containing image name, default = name . y_col : Name of column for labels, default = labels . targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical , in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input . color_mode : grayscale for black and white or grayscale, rgb for three color channels. batch_size : Number of images to be yielded from the generator per batch. If training fails lower this number. augmentation : : [Optional] : Default = True : Perform augmentation on Dataset shuffle : : [Optional] : Default = True : Shuffle Dataset seed : : [Optional] : Default = 23 : Initialize Random Seed Returns None : Initializes Test and Train Data Generators","title":"Data Processing Pipeline"},{"location":"medicalai/dataset_processors/#medicalaichiefdataset_prepare","text":"","title":"medicalai.chief.dataset_prepare"},{"location":"medicalai/dataset_processors/#datasetfromfolder","text":"datasetFromFolder ( self , folder , targetDim = ( 31 , 31 ), normalize = False , name = None , useCache = True , forceCleanCache = False ) TODO: Fix samplingMethodName assignment","title":"datasetFromFolder"},{"location":"medicalai/dataset_processors/#datasetgenfromfolder","text":"datasetGenFromFolder ( self , folder , targetDim = ( 224 , 224 ), normalize = False , batch_size = 16 , augmentation = True , color_mode = 'rgb' , class_mode = 'sparse' , shuffle = True , seed = 23 ) Create a dataset generator from dataset present in Folder. The folder should consist of test and train folders and each of the folders should have n classes of folders. Arguments folder : The directory must be set to the path where your n classes of folders are present. targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical , in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input . color_mode : grayscale for black and white or grayscale, rgb for three color channels. batch_size : Number of images to be yielded from the generator per batch. If training fails lower this number. augmentation : : [Optional] : Default = True : Perform augmentation on Dataset shuffle : : [Optional] : Default = True : Shuffle Dataset seed : : [Optional] : Default = 23 : Initialize Random Seed Returns None : Initializes Test and Train Data Generators","title":"datasetGenFromFolder"},{"location":"medicalai/dataset_processors/#datasetgenfromdataframe","text":"datasetGenFromDataframe ( self , folder , csv_path = '.' , x_col = 'name' , y_col = 'labels' , targetDim = ( 224 , 224 ), normalize = False , batch_size = 16 , augmentation = True , color_mode = 'rgb' , class_mode = 'sparse' , shuffle = True , seed = 17 ) Creates Keras Dataset Generator for Handling Large Datasets from DataFrame. Arguments csv_path : folder containing train.csv and test.csv. folder : The directory must be set to the path where your training images are present. x_col : Name of column containing image name, default = name . y_col : Name of column for labels, default = labels . targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical , in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input . color_mode : grayscale for black and white or grayscale, rgb for three color channels. batch_size : Number of images to be yielded from the generator per batch. If training fails lower this number. augmentation : : [Optional] : Default = True : Perform augmentation on Dataset shuffle : : [Optional] : Default = True : Shuffle Dataset seed : : [Optional] : Default = 23 : Initialize Random Seed Returns None : Initializes Test and Train Data Generators","title":"datasetGenFromDataframe"},{"location":"medicalai/medicalai.chief/","text":"medicalai.chief package \u00b6 Subpackages \u00b6 medicalai.chief.model_metrics package Submodules medicalai.chief.model_metrics.modelstats module Module contents medicalai.chief.nnets package Submodules medicalai.chief.nnets.covid_net module medicalai.chief.nnets.densenet module medicalai.chief.nnets.inceptionResnet module medicalai.chief.nnets.inceptionv3 module medicalai.chief.nnets.mobilenet module medicalai.chief.nnets.mobilenetv2 module medicalai.chief.nnets.resnet module medicalai.chief.nnets.vgg16 module medicalai.chief.nnets.xception module Module contents medicalai.chief.xai package Submodules medicalai.chief.xai.xcams module Module contents Submodules \u00b6 medicalai.chief.core module \u00b6 class medicalai.chief.core.INFERENCE_ENGINE(modelName, testSet=None, classNames=None) \u00b6 Bases: object TODO: Need to add Metaloader support decode_predictions(pred, top_preds=4, retType='tuple') \u00b6 explain(input, predictions=None, layer_to_explain='CNN3', classNames=None, selectedClasses=None, expectedClass=None, showPlot=False) \u00b6 generate_evaluation_report(testSet=None, predictions=None, printStat=False, returnPlot=False, showPlot=False, pdfName=None, **kwargs) \u00b6 getLayerNames() \u00b6 load_model_and_weights(modelName) \u00b6 load_network(fileName) \u00b6 load_weights(wgtfileName) \u00b6 predict(input) \u00b6 predict_pipeline(input) \u00b6 Slightly Faster version of predict. Useful for deployment. preprocessor_from_meta(metaFile=None) \u00b6 summary() \u00b6 class medicalai.chief.core.TRAIN_ENGINE(modelName=None) \u00b6 Bases: medicalai.chief.core.INFERENCE_ENGINE plot_train_acc_loss() \u00b6 train_and_save_model(AI_NAME, MODEL_SAVE_NAME, trainSet, testSet, OUTPUT_CLASSES, RETRAIN_MODEL, BATCH_SIZE, EPOCHS, LEARNING_RATE, convLayers=None, SAVE_BEST_MODEL=True, BEST_MODEL_COND=None, callbacks=None, loss='sparse_categorical_crossentropy', metrics=['accuracy'], showModel=False, CLASS_WEIGHTS=None) \u00b6 \u201d CLASS_WEIGHTS: Dictionary containing class weights for model.fit() medicalai.chief.core.check_model_exists(outputName) \u00b6 medicalai.chief.core.create_model_output_folder(outputName) \u00b6 medicalai.chief.core.decode_predictions(pred, labelNames, top_preds=4, retType='tuple') \u00b6 medicalai.chief.core.load_model_and_weights(modelName, summary=False) \u00b6 medicalai.chief.core.modelManager(modelName, x_train, OUTPUT_CLASSES, RETRAIN_MODEL, AI_NAME='tinyMedNet', convLayers=None) \u00b6 medicalai.chief.core.plot_training_metrics(result, theme='light') \u00b6 medicalai.chief.core.predict_labels(model, input, expected_output=None, labelNames=None, top_preds=4) \u00b6 predict(x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False) medicalai.chief.core.save_model_and_weights(model, outputName) \u00b6 medicalai.chief.core.show_model_details(model) \u00b6 medicalai.chief.core.train(model, x_train, batch_size=1, epochs=1, learning_rate=0.001, callbacks=None, class_weights=None, saveBestModel=False, bestModelCond=None, validation_data=None, TRAIN_STEPS=None, TEST_STEPS=None, loss='sparse_categorical_crossentropy', metrics=['accuracy'], verbose=None, y_train=None) \u00b6 medicalai.chief.dataset_prepare module \u00b6 class medicalai.chief.dataset_prepare.AUGMENTATION(rotation_range=12, fill_mode='constant', width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=False, vertical_flip=False, brightness_range=(0.9, 1.1), zoom_range=(0.85, 1.15), rescale=0.00392156862745098, shear_range=0, channel_shift_range=0, samplewise_center=False, samplewise_std_normalization=False, featurewise_center=False, featurewise_std_normalization=False, cval=0, preprocessing_function=None) \u00b6 Bases: object create_aug() \u00b6 class medicalai.chief.dataset_prepare.INPUT_PROCESSOR(targetDim=(31, 31), samplingMethod=None, normalize=False, color_mode='RGB', rescale=None, dtype='float32') \u00b6 Bases: object processImage(image) \u00b6 resizeDataSet(dataset) \u00b6 resizeDataSetfromFolder(folder) \u00b6 class medicalai.chief.dataset_prepare.InputProcessorFromMeta(metaFile) \u00b6 Bases: medicalai.chief.dataset_prepare.INPUT_PROCESSOR medicalai.chief.dataset_prepare.convertlist2tuple(lst) \u00b6 medicalai.chief.dataset_prepare.datasetFolderStructureValidate(folder) \u00b6 class medicalai.chief.dataset_prepare.datasetFromFolder(folder, targetDim=(31, 31), normalize=False, name=None, useCache=True, forceCleanCache=False) \u00b6 Bases: medicalai.chief.dataset_prepare.datasetManager TODO: Fix samplingMethodName assignment load_dataset() \u00b6 class medicalai.chief.dataset_prepare.datasetGenFromDataframe(folder, csv_path='.', x_col='name', y_col='labels', targetDim=(224, 224), normalize=False, batch_size=16, augmentation=True, color_mode='rgb', class_mode='sparse', shuffle=True, seed=17) \u00b6 Bases: object Creates Keras Dataset Generator for Handling Large Datasets from DataFrame. Parameters csv_path \u2013 folder containing train.csv and test.csv. folder \u2013 The directory must be set to the path where your training images are present. x_col \u2013 Name of column containing image name, default = name. y_col \u2013 Name of column for labels, default = labels. targetDim \u2013 The target_size is the size of your input images to the neural network. class_mode \u2013 Set binary if classifying only two classes, if not set to categorical, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input. color_mode \u2013 grayscale for black and white or grayscale, rgb for three color channels. batch_size \u2013 Number of images to be yielded from the generator per batch. If training fails lower this number. get_class_weights() \u00b6 get_numpy(generator) \u00b6 load_generator() \u00b6 class medicalai.chief.dataset_prepare.datasetGenFromFolder(folder, targetDim=(224, 224), normalize=False, batch_size=16, augmentation=True, color_mode='rgb', class_mode='sparse', shuffle=True, seed=17) \u00b6 Bases: object folder : The directory must be set to the path where your n classes of folders are present. targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input. color_mode: grayscale for black and white or grayscale, rgb for three color channels. batch_size: Number of images to be yielded from the generator per batch. If training fails lower this number. get_class_weights() \u00b6 get_numpy(generator) \u00b6 load_generator() \u00b6 class medicalai.chief.dataset_prepare.datasetManager(folder, targetDim=(31, 31), normalize=False, name=None, useCache=True, forceCleanCache=False) \u00b6 Bases: medicalai.chief.dataset_prepare.INPUT_PROCESSOR compress_and_cache_data(**kw) \u00b6 convert_dataset(**kw) \u00b6 load_data() \u00b6 process_dataset() \u00b6 reload_data(**kw) \u00b6 medicalai.chief.dataset_prepare.datasetManagerFunc(folder, targetDim=(31, 31), normalize=False) \u00b6 medicalai.chief.dataset_prepare.getLabelsFromFolder(folder) \u00b6 class medicalai.chief.dataset_prepare.medicalai_generator() \u00b6 Bases: tensorflow.python.keras.preprocessing.image.ImageDataGenerator medicalai.chief.dataset_prepare.metaLoader(metaFile) \u00b6 medicalai.chief.dataset_prepare.metaSaver(labelMap, labels, normalize=None, rescale=None, network_input_dim=None, samplingMethodName=None, outputName=None) \u00b6 class medicalai.chief.dataset_prepare.myDict() \u00b6 Bases: dict medicalai.chief.dataset_prepare.safe_labelmap_converter(labelMap) \u00b6 medicalai.chief.download_utils module \u00b6 class medicalai.chief.download_utils.DLProgress(iterable=None, desc=None, total=None, leave=True, file=None, ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None, ascii=None, disable=False, unit='it', unit_scale=False, dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0, position=None, postfix=None, unit_divisor=1000, write_bytes=None, gui=False, **kwargs) \u00b6 Bases: tqdm._tqdm.tqdm hook(block_num=1, block_size=1, total_size=None) \u00b6 last_block( = 0) \u00b6 medicalai.chief.download_utils.check_if_url(x) \u00b6 medicalai.chief.download_utils.getFile(url, storePath=None, cacheDir=None, subDir='dataset') \u00b6 medicalai.chief.download_utils.load_image(link, target_size=(32, 32), storePath=None, cacheDir=None, subDir='images') \u00b6 medicalai.chief.download_utils.untar(tar_file, destination) \u00b6 medicalai.chief.download_utils.unzip(zip_file, destination) \u00b6 medicalai.chief.networks module \u00b6 class medicalai.chief.networks.DenseNet121() \u00b6 Bases: medicalai.chief.networks.NetworkInit DenseNet121 model, with weights pre-trained on ImageNet inputSize: input image size tuple outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.InceptionResNetV2() \u00b6 Bases: medicalai.chief.networks.NetworkInit InceptionResNetV2 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.InceptionV3() \u00b6 Bases: medicalai.chief.networks.NetworkInit InceptionV3 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.MobileNet() \u00b6 Bases: medicalai.chief.networks.NetworkInit MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.MobileNetV2() \u00b6 Bases: medicalai.chief.networks.NetworkInit MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.NetworkInit() \u00b6 Bases: object Base class for parameter Network initializers. The NetworkInit class represents a network initializer used to initialize network/model parameters for numerous medical ai networks. It should be subclassed when implementing new types of network initializers. call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.VGG16() \u00b6 Bases: medicalai.chief.networks.NetworkInit VGG16 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.Xception() \u00b6 Bases: medicalai.chief.networks.NetworkInit Xception model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. medicalai.chief.networks.get(networkInitialization) \u00b6 class medicalai.chief.networks.megaNet() \u00b6 Bases: medicalai.chief.networks.NetworkInit megaNet is based on COVID-NET. This is a tensorflow 2.0 network variant for COVID-Net described in Paper \u201cCOVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\u201d by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/ call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.resNet110() \u00b6 Bases: medicalai.chief.networks.NetworkInit resnet110 call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.resNet20() \u00b6 Bases: medicalai.chief.networks.NetworkInit resnet20 call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.resNet32() \u00b6 Bases: medicalai.chief.networks.NetworkInit resnet32 call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.resNet56() \u00b6 Bases: medicalai.chief.networks.NetworkInit RESNET56 call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.tinyMedNet() \u00b6 Bases: medicalai.chief.networks.NetworkInit tinyMedNet is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library. call(inputSize, OutputSize, convLayers=None) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.tinyMedNet_v2() \u00b6 Bases: medicalai.chief.networks.NetworkInit tinyMedNet_v2 allows users to configure the number of Conv/CNN layers. tinyMedNet_v2 is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library. call(inputSize, OutputSize, convLayers=2) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. class medicalai.chief.networks.tinyMedNet_v3() \u00b6 Bases: medicalai.chief.networks.NetworkInit tinyMedNet_v3 has 3 FC layers with Dropout and Configurable number of Conv/CNN Layers. call(inputSize, OutputSize, convLayers=2) \u00b6 Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array. medicalai.chief.prettyloss module \u00b6 class medicalai.chief.prettyloss.prettyLoss(show_percentage=False) \u00b6 Bases: object STYLE( = {'bold': '\\x1b[1m', 'green': '\\x1b[32m', 'red': '\\x1b[91m'}) \u00b6 STYLE_END( = '\\x1b[0m') \u00b6 medicalai.chief.uFuncs module \u00b6 medicalai.chief.uFuncs.timeit(func) \u00b6 Module contents \u00b6","title":"medicalai.chief package"},{"location":"medicalai/medicalai.chief/#medicalaichief-package","text":"","title":"medicalai.chief package"},{"location":"medicalai/medicalai.chief/#subpackages","text":"medicalai.chief.model_metrics package Submodules medicalai.chief.model_metrics.modelstats module Module contents medicalai.chief.nnets package Submodules medicalai.chief.nnets.covid_net module medicalai.chief.nnets.densenet module medicalai.chief.nnets.inceptionResnet module medicalai.chief.nnets.inceptionv3 module medicalai.chief.nnets.mobilenet module medicalai.chief.nnets.mobilenetv2 module medicalai.chief.nnets.resnet module medicalai.chief.nnets.vgg16 module medicalai.chief.nnets.xception module Module contents medicalai.chief.xai package Submodules medicalai.chief.xai.xcams module Module contents","title":"Subpackages"},{"location":"medicalai/medicalai.chief/#submodules","text":"","title":"Submodules"},{"location":"medicalai/medicalai.chief/#medicalaichiefcore-module","text":"","title":"medicalai.chief.core module"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefcoreinference_enginemodelname-testsetnone-classnamesnone","text":"Bases: object TODO: Need to add Metaloader support","title":"class medicalai.chief.core.INFERENCE_ENGINE(modelName, testSet=None, classNames=None)"},{"location":"medicalai/medicalai.chief/#decode_predictionspred-top_preds4-rettypetuple","text":"","title":"decode_predictions(pred, top_preds=4, retType='tuple')"},{"location":"medicalai/medicalai.chief/#explaininput-predictionsnone-layer_to_explaincnn3-classnamesnone-selectedclassesnone-expectedclassnone-showplotfalse","text":"","title":"explain(input, predictions=None, layer_to_explain='CNN3', classNames=None, selectedClasses=None, expectedClass=None, showPlot=False)"},{"location":"medicalai/medicalai.chief/#generate_evaluation_reporttestsetnone-predictionsnone-printstatfalse-returnplotfalse-showplotfalse-pdfnamenone-kwargs","text":"","title":"generate_evaluation_report(testSet=None, predictions=None, printStat=False, returnPlot=False, showPlot=False, pdfName=None, **kwargs)"},{"location":"medicalai/medicalai.chief/#getlayernames","text":"","title":"getLayerNames()"},{"location":"medicalai/medicalai.chief/#load_model_and_weightsmodelname","text":"","title":"load_model_and_weights(modelName)"},{"location":"medicalai/medicalai.chief/#load_networkfilename","text":"","title":"load_network(fileName)"},{"location":"medicalai/medicalai.chief/#load_weightswgtfilename","text":"","title":"load_weights(wgtfileName)"},{"location":"medicalai/medicalai.chief/#predictinput","text":"","title":"predict(input)"},{"location":"medicalai/medicalai.chief/#predict_pipelineinput","text":"Slightly Faster version of predict. Useful for deployment.","title":"predict_pipeline(input)"},{"location":"medicalai/medicalai.chief/#preprocessor_from_metametafilenone","text":"","title":"preprocessor_from_meta(metaFile=None)"},{"location":"medicalai/medicalai.chief/#summary","text":"","title":"summary()"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefcoretrain_enginemodelnamenone","text":"Bases: medicalai.chief.core.INFERENCE_ENGINE","title":"class medicalai.chief.core.TRAIN_ENGINE(modelName=None)"},{"location":"medicalai/medicalai.chief/#plot_train_acc_loss","text":"","title":"plot_train_acc_loss()"},{"location":"medicalai/medicalai.chief/#train_and_save_modelai_name-model_save_name-trainset-testset-output_classes-retrain_model-batch_size-epochs-learning_rate-convlayersnone-save_best_modeltrue-best_model_condnone-callbacksnone-losssparse_categorical_crossentropy-metricsaccuracy-showmodelfalse-class_weightsnone","text":"\u201d CLASS_WEIGHTS: Dictionary containing class weights for model.fit()","title":"train_and_save_model(AI_NAME, MODEL_SAVE_NAME, trainSet, testSet, OUTPUT_CLASSES, RETRAIN_MODEL, BATCH_SIZE, EPOCHS, LEARNING_RATE, convLayers=None, SAVE_BEST_MODEL=True, BEST_MODEL_COND=None, callbacks=None, loss='sparse_categorical_crossentropy', metrics=['accuracy'], showModel=False, CLASS_WEIGHTS=None)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcorecheck_model_existsoutputname","text":"","title":"medicalai.chief.core.check_model_exists(outputName)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcorecreate_model_output_folderoutputname","text":"","title":"medicalai.chief.core.create_model_output_folder(outputName)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoredecode_predictionspred-labelnames-top_preds4-rettypetuple","text":"","title":"medicalai.chief.core.decode_predictions(pred, labelNames, top_preds=4, retType='tuple')"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoreload_model_and_weightsmodelname-summaryfalse","text":"","title":"medicalai.chief.core.load_model_and_weights(modelName, summary=False)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoremodelmanagermodelname-x_train-output_classes-retrain_model-ai_nametinymednet-convlayersnone","text":"","title":"medicalai.chief.core.modelManager(modelName, x_train, OUTPUT_CLASSES, RETRAIN_MODEL, AI_NAME='tinyMedNet', convLayers=None)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoreplot_training_metricsresult-themelight","text":"","title":"medicalai.chief.core.plot_training_metrics(result, theme='light')"},{"location":"medicalai/medicalai.chief/#medicalaichiefcorepredict_labelsmodel-input-expected_outputnone-labelnamesnone-top_preds4","text":"predict(x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)","title":"medicalai.chief.core.predict_labels(model, input, expected_output=None, labelNames=None, top_preds=4)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoresave_model_and_weightsmodel-outputname","text":"","title":"medicalai.chief.core.save_model_and_weights(model, outputName)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoreshow_model_detailsmodel","text":"","title":"medicalai.chief.core.show_model_details(model)"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoretrainmodel-x_train-batch_size1-epochs1-learning_rate0001-callbacksnone-class_weightsnone-savebestmodelfalse-bestmodelcondnone-validation_datanone-train_stepsnone-test_stepsnone-losssparse_categorical_crossentropy-metricsaccuracy-verbosenone-y_trainnone","text":"","title":"medicalai.chief.core.train(model, x_train, batch_size=1, epochs=1, learning_rate=0.001, callbacks=None, class_weights=None, saveBestModel=False, bestModelCond=None, validation_data=None, TRAIN_STEPS=None, TEST_STEPS=None, loss='sparse_categorical_crossentropy', metrics=['accuracy'], verbose=None, y_train=None)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_prepare-module","text":"","title":"medicalai.chief.dataset_prepare module"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_prepareaugmentationrotation_range12-fill_modeconstant-width_shift_range01-height_shift_range01-horizontal_flipfalse-vertical_flipfalse-brightness_range09-11-zoom_range085-115-rescale000392156862745098-shear_range0-channel_shift_range0-samplewise_centerfalse-samplewise_std_normalizationfalse-featurewise_centerfalse-featurewise_std_normalizationfalse-cval0-preprocessing_functionnone","text":"Bases: object","title":"class medicalai.chief.dataset_prepare.AUGMENTATION(rotation_range=12, fill_mode='constant', width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=False, vertical_flip=False, brightness_range=(0.9, 1.1), zoom_range=(0.85, 1.15), rescale=0.00392156862745098, shear_range=0, channel_shift_range=0, samplewise_center=False, samplewise_std_normalization=False, featurewise_center=False, featurewise_std_normalization=False, cval=0, preprocessing_function=None)"},{"location":"medicalai/medicalai.chief/#create_aug","text":"","title":"create_aug()"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_prepareinput_processortargetdim31-31-samplingmethodnone-normalizefalse-color_modergb-rescalenone-dtypefloat32","text":"Bases: object","title":"class medicalai.chief.dataset_prepare.INPUT_PROCESSOR(targetDim=(31, 31), samplingMethod=None, normalize=False, color_mode='RGB', rescale=None, dtype='float32')"},{"location":"medicalai/medicalai.chief/#processimageimage","text":"","title":"processImage(image)"},{"location":"medicalai/medicalai.chief/#resizedatasetdataset","text":"","title":"resizeDataSet(dataset)"},{"location":"medicalai/medicalai.chief/#resizedatasetfromfolderfolder","text":"","title":"resizeDataSetfromFolder(folder)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_prepareinputprocessorfrommetametafile","text":"Bases: medicalai.chief.dataset_prepare.INPUT_PROCESSOR","title":"class medicalai.chief.dataset_prepare.InputProcessorFromMeta(metaFile)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_prepareconvertlist2tuplelst","text":"","title":"medicalai.chief.dataset_prepare.convertlist2tuple(lst)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparedatasetfolderstructurevalidatefolder","text":"","title":"medicalai.chief.dataset_prepare.datasetFolderStructureValidate(folder)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetfromfolderfolder-targetdim31-31-normalizefalse-namenone-usecachetrue-forcecleancachefalse","text":"Bases: medicalai.chief.dataset_prepare.datasetManager TODO: Fix samplingMethodName assignment","title":"class medicalai.chief.dataset_prepare.datasetFromFolder(folder, targetDim=(31, 31), normalize=False, name=None, useCache=True, forceCleanCache=False)"},{"location":"medicalai/medicalai.chief/#load_dataset","text":"","title":"load_dataset()"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetgenfromdataframefolder-csv_path-x_colname-y_collabels-targetdim224-224-normalizefalse-batch_size16-augmentationtrue-color_modergb-class_modesparse-shuffletrue-seed17","text":"Bases: object Creates Keras Dataset Generator for Handling Large Datasets from DataFrame. Parameters csv_path \u2013 folder containing train.csv and test.csv. folder \u2013 The directory must be set to the path where your training images are present. x_col \u2013 Name of column containing image name, default = name. y_col \u2013 Name of column for labels, default = labels. targetDim \u2013 The target_size is the size of your input images to the neural network. class_mode \u2013 Set binary if classifying only two classes, if not set to categorical, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input. color_mode \u2013 grayscale for black and white or grayscale, rgb for three color channels. batch_size \u2013 Number of images to be yielded from the generator per batch. If training fails lower this number.","title":"class medicalai.chief.dataset_prepare.datasetGenFromDataframe(folder, csv_path='.', x_col='name', y_col='labels', targetDim=(224, 224), normalize=False, batch_size=16, augmentation=True, color_mode='rgb', class_mode='sparse', shuffle=True, seed=17)"},{"location":"medicalai/medicalai.chief/#get_class_weights","text":"","title":"get_class_weights()"},{"location":"medicalai/medicalai.chief/#get_numpygenerator","text":"","title":"get_numpy(generator)"},{"location":"medicalai/medicalai.chief/#load_generator","text":"","title":"load_generator()"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetgenfromfolderfolder-targetdim224-224-normalizefalse-batch_size16-augmentationtrue-color_modergb-class_modesparse-shuffletrue-seed17","text":"Bases: object folder : The directory must be set to the path where your n classes of folders are present. targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input. color_mode: grayscale for black and white or grayscale, rgb for three color channels. batch_size: Number of images to be yielded from the generator per batch. If training fails lower this number.","title":"class medicalai.chief.dataset_prepare.datasetGenFromFolder(folder, targetDim=(224, 224), normalize=False, batch_size=16, augmentation=True, color_mode='rgb', class_mode='sparse', shuffle=True, seed=17)"},{"location":"medicalai/medicalai.chief/#get_class_weights_1","text":"","title":"get_class_weights()"},{"location":"medicalai/medicalai.chief/#get_numpygenerator_1","text":"","title":"get_numpy(generator)"},{"location":"medicalai/medicalai.chief/#load_generator_1","text":"","title":"load_generator()"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetmanagerfolder-targetdim31-31-normalizefalse-namenone-usecachetrue-forcecleancachefalse","text":"Bases: medicalai.chief.dataset_prepare.INPUT_PROCESSOR","title":"class medicalai.chief.dataset_prepare.datasetManager(folder, targetDim=(31, 31), normalize=False, name=None, useCache=True, forceCleanCache=False)"},{"location":"medicalai/medicalai.chief/#compress_and_cache_datakw","text":"","title":"compress_and_cache_data(**kw)"},{"location":"medicalai/medicalai.chief/#convert_datasetkw","text":"","title":"convert_dataset(**kw)"},{"location":"medicalai/medicalai.chief/#load_data","text":"","title":"load_data()"},{"location":"medicalai/medicalai.chief/#process_dataset","text":"","title":"process_dataset()"},{"location":"medicalai/medicalai.chief/#reload_datakw","text":"","title":"reload_data(**kw)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparedatasetmanagerfuncfolder-targetdim31-31-normalizefalse","text":"","title":"medicalai.chief.dataset_prepare.datasetManagerFunc(folder, targetDim=(31, 31), normalize=False)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparegetlabelsfromfolderfolder","text":"","title":"medicalai.chief.dataset_prepare.getLabelsFromFolder(folder)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparemedicalai_generator","text":"Bases: tensorflow.python.keras.preprocessing.image.ImageDataGenerator","title":"class medicalai.chief.dataset_prepare.medicalai_generator()"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparemetaloadermetafile","text":"","title":"medicalai.chief.dataset_prepare.metaLoader(metaFile)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparemetasaverlabelmap-labels-normalizenone-rescalenone-network_input_dimnone-samplingmethodnamenone-outputnamenone","text":"","title":"medicalai.chief.dataset_prepare.metaSaver(labelMap, labels, normalize=None, rescale=None, network_input_dim=None, samplingMethodName=None, outputName=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparemydict","text":"Bases: dict","title":"class medicalai.chief.dataset_prepare.myDict()"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparesafe_labelmap_converterlabelmap","text":"","title":"medicalai.chief.dataset_prepare.safe_labelmap_converter(labelMap)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utils-module","text":"","title":"medicalai.chief.download_utils module"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdownload_utilsdlprogressiterablenone-descnone-totalnone-leavetrue-filenone-ncolsnone-mininterval01-maxinterval100-minitersnone-asciinone-disablefalse-unitit-unit_scalefalse-dynamic_ncolsfalse-smoothing03-bar_formatnone-initial0-positionnone-postfixnone-unit_divisor1000-write_bytesnone-guifalse-kwargs","text":"Bases: tqdm._tqdm.tqdm","title":"class medicalai.chief.download_utils.DLProgress(iterable=None, desc=None, total=None, leave=True, file=None, ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None, ascii=None, disable=False, unit='it', unit_scale=False, dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0, position=None, postfix=None, unit_divisor=1000, write_bytes=None, gui=False, **kwargs)"},{"location":"medicalai/medicalai.chief/#hookblock_num1-block_size1-total_sizenone","text":"","title":"hook(block_num=1, block_size=1, total_size=None)"},{"location":"medicalai/medicalai.chief/#last_block-0","text":"","title":"last_block( = 0)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilscheck_if_urlx","text":"","title":"medicalai.chief.download_utils.check_if_url(x)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsgetfileurl-storepathnone-cachedirnone-subdirdataset","text":"","title":"medicalai.chief.download_utils.getFile(url, storePath=None, cacheDir=None, subDir='dataset')"},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsload_imagelink-target_size32-32-storepathnone-cachedirnone-subdirimages","text":"","title":"medicalai.chief.download_utils.load_image(link, target_size=(32, 32), storePath=None, cacheDir=None, subDir='images')"},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsuntartar_file-destination","text":"","title":"medicalai.chief.download_utils.untar(tar_file, destination)"},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsunzipzip_file-destination","text":"","title":"medicalai.chief.download_utils.unzip(zip_file, destination)"},{"location":"medicalai/medicalai.chief/#medicalaichiefnetworks-module","text":"","title":"medicalai.chief.networks module"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksdensenet121","text":"Bases: medicalai.chief.networks.NetworkInit DenseNet121 model, with weights pre-trained on ImageNet inputSize: input image size tuple outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.DenseNet121()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksinceptionresnetv2","text":"Bases: medicalai.chief.networks.NetworkInit InceptionResNetV2 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.InceptionResNetV2()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_1","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksinceptionv3","text":"Bases: medicalai.chief.networks.NetworkInit InceptionV3 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.InceptionV3()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_2","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksmobilenet","text":"Bases: medicalai.chief.networks.NetworkInit MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.MobileNet()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_3","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksmobilenetv2","text":"Bases: medicalai.chief.networks.NetworkInit MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.MobileNetV2()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_4","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksnetworkinit","text":"Bases: object Base class for parameter Network initializers. The NetworkInit class represents a network initializer used to initialize network/model parameters for numerous medical ai networks. It should be subclassed when implementing new types of network initializers.","title":"class medicalai.chief.networks.NetworkInit()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_5","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksvgg16","text":"Bases: medicalai.chief.networks.NetworkInit VGG16 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.VGG16()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_6","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksxception","text":"Bases: medicalai.chief.networks.NetworkInit Xception model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"class medicalai.chief.networks.Xception()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_7","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#medicalaichiefnetworksgetnetworkinitialization","text":"","title":"medicalai.chief.networks.get(networkInitialization)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksmeganet","text":"Bases: medicalai.chief.networks.NetworkInit megaNet is based on COVID-NET. This is a tensorflow 2.0 network variant for COVID-Net described in Paper \u201cCOVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\u201d by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/","title":"class medicalai.chief.networks.megaNet()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_8","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet110","text":"Bases: medicalai.chief.networks.NetworkInit resnet110","title":"class medicalai.chief.networks.resNet110()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_9","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet20","text":"Bases: medicalai.chief.networks.NetworkInit resnet20","title":"class medicalai.chief.networks.resNet20()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_10","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet32","text":"Bases: medicalai.chief.networks.NetworkInit resnet32","title":"class medicalai.chief.networks.resNet32()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_11","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet56","text":"Bases: medicalai.chief.networks.NetworkInit RESNET56","title":"class medicalai.chief.networks.resNet56()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_12","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworkstinymednet","text":"Bases: medicalai.chief.networks.NetworkInit tinyMedNet is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.","title":"class medicalai.chief.networks.tinyMedNet()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_13","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=None)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworkstinymednet_v2","text":"Bases: medicalai.chief.networks.NetworkInit tinyMedNet_v2 allows users to configure the number of Conv/CNN layers. tinyMedNet_v2 is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.","title":"class medicalai.chief.networks.tinyMedNet_v2()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayers2","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=2)"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworkstinymednet_v3","text":"Bases: medicalai.chief.networks.NetworkInit tinyMedNet_v3 has 3 FC layers with Dropout and Configurable number of Conv/CNN Layers.","title":"class medicalai.chief.networks.tinyMedNet_v3()"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayers2_1","text":"Sample should return model initialized with input and output Sizes. Parameters inputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the input of network. OutputSize ( tuple* or **int.*) \u2013 Integer or tuple specifying the output classes of network. Returns Initialized Model. Return type numpy.array.","title":"call(inputSize, OutputSize, convLayers=2)"},{"location":"medicalai/medicalai.chief/#medicalaichiefprettyloss-module","text":"","title":"medicalai.chief.prettyloss module"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefprettylossprettylossshow_percentagefalse","text":"Bases: object","title":"class medicalai.chief.prettyloss.prettyLoss(show_percentage=False)"},{"location":"medicalai/medicalai.chief/#style-bold-x1b1m-green-x1b32m-red-x1b91m","text":"","title":"STYLE( = {'bold': '\\x1b[1m', 'green': '\\x1b[32m', 'red': '\\x1b[91m'})"},{"location":"medicalai/medicalai.chief/#style_end-x1b0m","text":"","title":"STYLE_END( = '\\x1b[0m')"},{"location":"medicalai/medicalai.chief/#medicalaichiefufuncs-module","text":"","title":"medicalai.chief.uFuncs module"},{"location":"medicalai/medicalai.chief/#medicalaichiefufuncstimeitfunc","text":"","title":"medicalai.chief.uFuncs.timeit(func)"},{"location":"medicalai/medicalai.chief/#module-contents","text":"","title":"Module contents"},{"location":"medicalai/medicalai.chief.model_metrics/","text":"medicalai.chief.model_metrics package \u00b6 Submodules \u00b6 medicalai.chief.model_metrics.modelstats module \u00b6 medicalai.chief.model_metrics.modelstats.bootstrap_auc(y, pred, classes, bootstraps=100, fold_size=1000) \u00b6 medicalai.chief.model_metrics.modelstats.classify_report(y_true, y_pred) \u00b6 medicalai.chief.model_metrics.modelstats.compute_class_freqs(labels) \u00b6 Compute positive and negative frequences for each class. Parameters labels ( np.array ) \u2013 matrix of labels, size (num_examples, num_classes) Returns array of positive frequences for each class, size (num_classes) negative_frequencies (np.array): array of negative frequences for each class, size (num_classes) Return type positive_frequencies (np.array) medicalai.chief.model_metrics.modelstats.confidence_intervals(class_labels, statistics) \u00b6 medicalai.chief.model_metrics.modelstats.false_negatives(expected, preds, threshold=0.5) \u00b6 Count false positives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) pred ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns false negatives Return type false_neg (int) medicalai.chief.model_metrics.modelstats.false_positives(expected, preds, threshold=0.5) \u00b6 Count false positives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns false positives Return type false_pos (int) medicalai.chief.model_metrics.modelstats.generate_evaluation_report(CLASS_NAMES, predictions, groundTruth=None, generator=None, returnPlot=True, showPlot=True, printStat=True, **kwargs) \u00b6 Generates Evaluation PDF Report for a Test/Validation experimentation. Ground truth needs to be passed to generate the pdf report. Parameters CLASS_NAMES ( list ) \u2013 List of Label names or class names of dataset. predictions ( np.array ) \u2013 Predicted output of test data. groundTruth ( np.array ) \u2013 Ground truth of test data. generator ( Optional ) \u2013 If generator method used in training, pass the generator. returnPlot ( Bool ) \u2013 Returns the plot handle if set to True showPlot ( Bool ) \u2013 Display the plot if set to True. [IMP: Until the plot is closed, the code execution is blocked.] printStat ( Bool ) \u2013 Print the statistics of the experiment on the console if set to True. T **kwargs ( Optional ) \u2013 Plot Setting Arguments Returns true positives Return type true_pos (int) medicalai.chief.model_metrics.modelstats.get_accuracy(expected, preds, threshold=0.9) \u00b6 Compute accuracy of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns accuracy of predictions at threshold Return type accuracy (float) medicalai.chief.model_metrics.modelstats.get_accuracy_score(test_labels, test_predictions) \u00b6 medicalai.chief.model_metrics.modelstats.get_curve(gt, pred, target_names, curve='roc', returnPlot=False, showPlot=True, axes=None, **kwargs) \u00b6 medicalai.chief.model_metrics.modelstats.get_false_neg(y, pred, th=0.5) \u00b6 medicalai.chief.model_metrics.modelstats.get_false_pos(y, pred, th=0.5) \u00b6 medicalai.chief.model_metrics.modelstats.get_npv(expected, preds, threshold=0.5) \u00b6 Compute NPV of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns negative predictive value of predictions at threshold Return type NPV (float) medicalai.chief.model_metrics.modelstats.get_performance_metrics(y, pred, class_labels, tp= , tn= , fp= , fn= , acc=None, prevalence=None, spec=None, sens=None, ppv=None, npv=None, auc=None, f1=None, thresholds=[]) \u00b6 medicalai.chief.model_metrics.modelstats.get_ppv(expected, preds, threshold=0.5) \u00b6 Compute PPV of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns positive predictive value of predictions at threshold Return type PPV (float) medicalai.chief.model_metrics.modelstats.get_prevalence(expected) \u00b6 Compute accuracy of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) Returns prevalence of positive cases Return type prevalence (float) medicalai.chief.model_metrics.modelstats.get_roc_curve(labels, predicted_vals, groundTruth=None, generator=None, returnPlot=False, showPlot=True, axes=None, **kwargs) \u00b6 medicalai.chief.model_metrics.modelstats.get_sensitivity(expected, preds, threshold=0.5) \u00b6 Compute sensitivity of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns probability that our test outputs positive given that the case is actually positive Return type sensitivity (float) medicalai.chief.model_metrics.modelstats.get_specificity(expected, preds, threshold=0.5) \u00b6 Compute specificity of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns probability that the test outputs negative given that the case is actually negative Return type specificity (float) medicalai.chief.model_metrics.modelstats.get_true_neg(y, pred, th=0.5) \u00b6 medicalai.chief.model_metrics.modelstats.get_true_pos(y, pred, th=0.5) \u00b6 medicalai.chief.model_metrics.modelstats.get_weighted_loss(pos_weights, neg_weights, epsilon=1e-07) \u00b6 Return weighted loss function given negative weights and positive weights. Parameters pos_weights ( np.array ) \u2013 array of positive weights for each class, size (num_classes) neg_weights ( np.array ) \u2013 array of negative weights for each class, size (num_classes) Returns weighted loss function Return type weighted_loss (function) medicalai.chief.model_metrics.modelstats.model_performance_metrics(y, pred, class_labels, tp= , tn= , fp= , fn= , thresholds=[]) \u00b6 medicalai.chief.model_metrics.modelstats.platt_scaling(y, pred, class_labels) \u00b6 medicalai.chief.model_metrics.modelstats.plot_calibration_curve(y, pred, class_labels) \u00b6 medicalai.chief.model_metrics.modelstats.plot_confusion_matrix(model=None, test_data=None, test_labels=None, labelNames=None, title='Confusion Matrix', predictions=None, showPlot=True, returnPlot=False) \u00b6 medicalai.chief.model_metrics.modelstats.print_classification_report(y_true, y_pred) \u00b6 medicalai.chief.model_metrics.modelstats.print_cohen_kappa_score(y_true, y_pred) \u00b6 medicalai.chief.model_metrics.modelstats.render_df_as_table(data, title='Table', col_width=3.0, row_height=0.625, font_size=18, header_color='#655EE5', row_colors=['#f1f1f2', 'w'], edge_color='w', bbox=[0, 0, 1, 1], header_columns=0, resetIndex=False, ax=None, **kwargs) \u00b6 medicalai.chief.model_metrics.modelstats.true_negatives(expected, preds, threshold=0.5) \u00b6 Count true negatives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns true negatives Return type true_neg (int) medicalai.chief.model_metrics.modelstats.true_positives(expected, preds, threshold=0.5) \u00b6 Count true positives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns true positives Return type true_pos (int) Module contents \u00b6","title":"medicalai.chief.model_metrics package"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metrics-package","text":"","title":"medicalai.chief.model_metrics package"},{"location":"medicalai/medicalai.chief.model_metrics/#submodules","text":"","title":"Submodules"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstats-module","text":"","title":"medicalai.chief.model_metrics.modelstats module"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsbootstrap_aucy-pred-classes-bootstraps100-fold_size1000","text":"","title":"medicalai.chief.model_metrics.modelstats.bootstrap_auc(y, pred, classes, bootstraps=100, fold_size=1000)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsclassify_reporty_true-y_pred","text":"","title":"medicalai.chief.model_metrics.modelstats.classify_report(y_true, y_pred)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatscompute_class_freqslabels","text":"Compute positive and negative frequences for each class. Parameters labels ( np.array ) \u2013 matrix of labels, size (num_examples, num_classes) Returns array of positive frequences for each class, size (num_classes) negative_frequencies (np.array): array of negative frequences for each class, size (num_classes) Return type positive_frequencies (np.array)","title":"medicalai.chief.model_metrics.modelstats.compute_class_freqs(labels)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsconfidence_intervalsclass_labels-statistics","text":"","title":"medicalai.chief.model_metrics.modelstats.confidence_intervals(class_labels, statistics)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsfalse_negativesexpected-preds-threshold05","text":"Count false positives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) pred ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns false negatives Return type false_neg (int)","title":"medicalai.chief.model_metrics.modelstats.false_negatives(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsfalse_positivesexpected-preds-threshold05","text":"Count false positives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns false positives Return type false_pos (int)","title":"medicalai.chief.model_metrics.modelstats.false_positives(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsgenerate_evaluation_reportclass_names-predictions-groundtruthnone-generatornone-returnplottrue-showplottrue-printstattrue-kwargs","text":"Generates Evaluation PDF Report for a Test/Validation experimentation. Ground truth needs to be passed to generate the pdf report. Parameters CLASS_NAMES ( list ) \u2013 List of Label names or class names of dataset. predictions ( np.array ) \u2013 Predicted output of test data. groundTruth ( np.array ) \u2013 Ground truth of test data. generator ( Optional ) \u2013 If generator method used in training, pass the generator. returnPlot ( Bool ) \u2013 Returns the plot handle if set to True showPlot ( Bool ) \u2013 Display the plot if set to True. [IMP: Until the plot is closed, the code execution is blocked.] printStat ( Bool ) \u2013 Print the statistics of the experiment on the console if set to True. T **kwargs ( Optional ) \u2013 Plot Setting Arguments Returns true positives Return type true_pos (int)","title":"medicalai.chief.model_metrics.modelstats.generate_evaluation_report(CLASS_NAMES, predictions, groundTruth=None, generator=None, returnPlot=True, showPlot=True, printStat=True, **kwargs)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_accuracyexpected-preds-threshold09","text":"Compute accuracy of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns accuracy of predictions at threshold Return type accuracy (float)","title":"medicalai.chief.model_metrics.modelstats.get_accuracy(expected, preds, threshold=0.9)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_accuracy_scoretest_labels-test_predictions","text":"","title":"medicalai.chief.model_metrics.modelstats.get_accuracy_score(test_labels, test_predictions)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_curvegt-pred-target_names-curveroc-returnplotfalse-showplottrue-axesnone-kwargs","text":"","title":"medicalai.chief.model_metrics.modelstats.get_curve(gt, pred, target_names, curve='roc', returnPlot=False, showPlot=True, axes=None, **kwargs)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_false_negy-pred-th05","text":"","title":"medicalai.chief.model_metrics.modelstats.get_false_neg(y, pred, th=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_false_posy-pred-th05","text":"","title":"medicalai.chief.model_metrics.modelstats.get_false_pos(y, pred, th=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_npvexpected-preds-threshold05","text":"Compute NPV of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns negative predictive value of predictions at threshold Return type NPV (float)","title":"medicalai.chief.model_metrics.modelstats.get_npv(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_performance_metricsy-pred-class_labels-tp-tn-fp-fn-accnone-prevalencenone-specnone-sensnone-ppvnone-npvnone-aucnone-f1none-thresholds","text":"","title":"medicalai.chief.model_metrics.modelstats.get_performance_metrics(y, pred, class_labels, tp=, tn=, fp=, fn=, acc=None, prevalence=None, spec=None, sens=None, ppv=None, npv=None, auc=None, f1=None, thresholds=[])"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_ppvexpected-preds-threshold05","text":"Compute PPV of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns positive predictive value of predictions at threshold Return type PPV (float)","title":"medicalai.chief.model_metrics.modelstats.get_ppv(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_prevalenceexpected","text":"Compute accuracy of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) Returns prevalence of positive cases Return type prevalence (float)","title":"medicalai.chief.model_metrics.modelstats.get_prevalence(expected)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_roc_curvelabels-predicted_vals-groundtruthnone-generatornone-returnplotfalse-showplottrue-axesnone-kwargs","text":"","title":"medicalai.chief.model_metrics.modelstats.get_roc_curve(labels, predicted_vals, groundTruth=None, generator=None, returnPlot=False, showPlot=True, axes=None, **kwargs)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_sensitivityexpected-preds-threshold05","text":"Compute sensitivity of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns probability that our test outputs positive given that the case is actually positive Return type sensitivity (float)","title":"medicalai.chief.model_metrics.modelstats.get_sensitivity(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_specificityexpected-preds-threshold05","text":"Compute specificity of predictions at threshold. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns probability that the test outputs negative given that the case is actually negative Return type specificity (float)","title":"medicalai.chief.model_metrics.modelstats.get_specificity(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_true_negy-pred-th05","text":"","title":"medicalai.chief.model_metrics.modelstats.get_true_neg(y, pred, th=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_true_posy-pred-th05","text":"","title":"medicalai.chief.model_metrics.modelstats.get_true_pos(y, pred, th=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_weighted_losspos_weights-neg_weights-epsilon1e-07","text":"Return weighted loss function given negative weights and positive weights. Parameters pos_weights ( np.array ) \u2013 array of positive weights for each class, size (num_classes) neg_weights ( np.array ) \u2013 array of negative weights for each class, size (num_classes) Returns weighted loss function Return type weighted_loss (function)","title":"medicalai.chief.model_metrics.modelstats.get_weighted_loss(pos_weights, neg_weights, epsilon=1e-07)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsmodel_performance_metricsy-pred-class_labels-tp-tn-fp-fn-thresholds","text":"","title":"medicalai.chief.model_metrics.modelstats.model_performance_metrics(y, pred, class_labels, tp=, tn=, fp=, fn=, thresholds=[])"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsplatt_scalingy-pred-class_labels","text":"","title":"medicalai.chief.model_metrics.modelstats.platt_scaling(y, pred, class_labels)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsplot_calibration_curvey-pred-class_labels","text":"","title":"medicalai.chief.model_metrics.modelstats.plot_calibration_curve(y, pred, class_labels)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsplot_confusion_matrixmodelnone-test_datanone-test_labelsnone-labelnamesnone-titleconfusion-matrix-predictionsnone-showplottrue-returnplotfalse","text":"","title":"medicalai.chief.model_metrics.modelstats.plot_confusion_matrix(model=None, test_data=None, test_labels=None, labelNames=None, title='Confusion Matrix', predictions=None, showPlot=True, returnPlot=False)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsprint_classification_reporty_true-y_pred","text":"","title":"medicalai.chief.model_metrics.modelstats.print_classification_report(y_true, y_pred)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsprint_cohen_kappa_scorey_true-y_pred","text":"","title":"medicalai.chief.model_metrics.modelstats.print_cohen_kappa_score(y_true, y_pred)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsrender_df_as_tabledata-titletable-col_width30-row_height0625-font_size18-header_color655ee5-row_colorsf1f1f2-w-edge_colorw-bbox0-0-1-1-header_columns0-resetindexfalse-axnone-kwargs","text":"","title":"medicalai.chief.model_metrics.modelstats.render_df_as_table(data, title='Table', col_width=3.0, row_height=0.625, font_size=18, header_color='#655EE5', row_colors=['#f1f1f2', 'w'], edge_color='w', bbox=[0, 0, 1, 1], header_columns=0, resetIndex=False, ax=None, **kwargs)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatstrue_negativesexpected-preds-threshold05","text":"Count true negatives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns true negatives Return type true_neg (int)","title":"medicalai.chief.model_metrics.modelstats.true_negatives(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatstrue_positivesexpected-preds-threshold05","text":"Count true positives. Parameters expected ( np.array ) \u2013 ground truth, size (n_examples) preds ( np.array ) \u2013 model output, size (n_examples) threshold ( float ) \u2013 cutoff value for positive prediction from model Returns true positives Return type true_pos (int)","title":"medicalai.chief.model_metrics.modelstats.true_positives(expected, preds, threshold=0.5)"},{"location":"medicalai/medicalai.chief.model_metrics/#module-contents","text":"","title":"Module contents"},{"location":"medicalai/medicalai.chief.nnets/","text":"medicalai.chief.nnets package \u00b6 Submodules \u00b6 medicalai.chief.nnets.covid_net module \u00b6 medicalai.chief.nnets.covid_net.COVIDNET_Keras(img_input=(224, 224, 3), classes=4) \u00b6 This is a tensorflow 2.0 network variant for COVID-Net described in Paper \u201cCOVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\u201d by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/ medicalai.chief.nnets.covid_net.PEPXModel(input_tensor, filters, name) \u00b6 medicalai.chief.nnets.densenet module \u00b6 medicalai.chief.nnets.densenet.DenseNet121_Model(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the DenseNet121 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model medicalai.chief.nnets.inceptionResnet module \u00b6 medicalai.chief.nnets.inceptionResnet.InceptionResNetV2_Model(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the InceptionResNetV2 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model medicalai.chief.nnets.inceptionv3 module \u00b6 medicalai.chief.nnets.inceptionv3.InceptionV3(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the InceptionV3 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model medicalai.chief.nnets.mobilenet module \u00b6 medicalai.chief.nnets.mobilenet.MobileNet(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the MobileNet network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model medicalai.chief.nnets.mobilenetv2 module \u00b6 medicalai.chief.nnets.mobilenetv2.MobileNetV2(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the MobileNetV2 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model medicalai.chief.nnets.resnet module \u00b6 medicalai.chief.nnets.resnet.conv_building_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), training=None) \u00b6 A block that has a conv layer at shortcut. Parameters input_tensor \u2013 input tensor kernel_size \u2013 default 3, the kernel size of middle conv layer at main path filters \u2013 list of integers, the filters of 3 conv layer at main path stage \u2013 integer, current stage label, used for generating layer names block \u2013 current block label, used for generating layer names strides \u2013 Strides for the first conv layer in the block. training \u2013 Only used if training keras model with Estimator. In other scenarios it is handled automatically. Returns Output tensor for the block. Note that from stage 3, the first conv layer at main path is with strides=(2, 2) And the shortcut should have strides=(2, 2) as well medicalai.chief.nnets.resnet.identity_building_block(input_tensor, kernel_size, filters, stage, block, training=None) \u00b6 The identity block is the block that has no conv layer at shortcut. Parameters input_tensor \u2013 input tensor kernel_size \u2013 default 3, the kernel size of middle conv layer at main path filters \u2013 list of integers, the filters of 3 conv layer at main path stage \u2013 integer, current stage label, used for generating layer names block \u2013 current block label, used for generating layer names training \u2013 Only used if training keras model with Estimator. In other scenarios it is handled automatically. Returns Output tensor for the block. medicalai.chief.nnets.resnet.resnet(num_blocks, img_input=None, classes=10, training=None) \u00b6 Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance. medicalai.chief.nnets.resnet.resnet110(*, num_blocks=110, img_input=None, classes=10, training=None) \u00b6 Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance. medicalai.chief.nnets.resnet.resnet20(*, num_blocks=3, img_input=None, classes=10, training=None) \u00b6 Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance. medicalai.chief.nnets.resnet.resnet32(*, num_blocks=5, img_input=None, classes=10, training=None) \u00b6 Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance. medicalai.chief.nnets.resnet.resnet56(*, num_blocks=9, img_input=None, classes=10, training=None) \u00b6 Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance. medicalai.chief.nnets.resnet.resnet_block(input_tensor, size, kernel_size, filters, stage, conv_strides=(2, 2), training=None) \u00b6 A block which applies conv followed by multiple identity blocks. Parameters input_tensor \u2013 input tensor size \u2013 integer, number of constituent conv/identity building blocks. conv block is applied once** , ****followed by** ( A ) \u2013 kernel_size \u2013 default 3, the kernel size of middle conv layer at main path filters \u2013 list of integers, the filters of 3 conv layer at main path stage \u2013 integer, current stage label, used for generating layer names conv_strides \u2013 Strides for the first conv layer in the block. training \u2013 Only used if training keras model with Estimator. In other scenarios it is handled automatically. Returns Output tensor after applying conv and identity blocks. medicalai.chief.nnets.vgg16 module \u00b6 medicalai.chief.nnets.vgg16.VGG16_Model(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the VGG16 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model medicalai.chief.nnets.xception module \u00b6 medicalai.chief.nnets.xception.Xception(img_input=(224, 224, 3), classes=3) \u00b6 Loaded the Xception network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model Module contents \u00b6","title":"medicalai.chief.nnets package"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnets-package","text":"","title":"medicalai.chief.nnets package"},{"location":"medicalai/medicalai.chief.nnets/#submodules","text":"","title":"Submodules"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetscovid_net-module","text":"","title":"medicalai.chief.nnets.covid_net module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetscovid_netcovidnet_kerasimg_input224-224-3-classes4","text":"This is a tensorflow 2.0 network variant for COVID-Net described in Paper \u201cCOVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\u201d by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/","title":"medicalai.chief.nnets.covid_net.COVIDNET_Keras(img_input=(224, 224, 3), classes=4)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetscovid_netpepxmodelinput_tensor-filters-name","text":"","title":"medicalai.chief.nnets.covid_net.PEPXModel(input_tensor, filters, name)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsdensenet-module","text":"","title":"medicalai.chief.nnets.densenet module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsdensenetdensenet121_modelimg_input224-224-3-classes3","text":"Loaded the DenseNet121 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.densenet.DenseNet121_Model(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionresnet-module","text":"","title":"medicalai.chief.nnets.inceptionResnet module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionresnetinceptionresnetv2_modelimg_input224-224-3-classes3","text":"Loaded the InceptionResNetV2 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.inceptionResnet.InceptionResNetV2_Model(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionv3-module","text":"","title":"medicalai.chief.nnets.inceptionv3 module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionv3inceptionv3img_input224-224-3-classes3","text":"Loaded the InceptionV3 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.inceptionv3.InceptionV3(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenet-module","text":"","title":"medicalai.chief.nnets.mobilenet module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenetmobilenetimg_input224-224-3-classes3","text":"Loaded the MobileNet network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.mobilenet.MobileNet(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenetv2-module","text":"","title":"medicalai.chief.nnets.mobilenetv2 module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenetv2mobilenetv2img_input224-224-3-classes3","text":"Loaded the MobileNetV2 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.mobilenetv2.MobileNetV2(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnet-module","text":"","title":"medicalai.chief.nnets.resnet module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetconv_building_blockinput_tensor-kernel_size-filters-stage-block-strides2-2-trainingnone","text":"A block that has a conv layer at shortcut. Parameters input_tensor \u2013 input tensor kernel_size \u2013 default 3, the kernel size of middle conv layer at main path filters \u2013 list of integers, the filters of 3 conv layer at main path stage \u2013 integer, current stage label, used for generating layer names block \u2013 current block label, used for generating layer names strides \u2013 Strides for the first conv layer in the block. training \u2013 Only used if training keras model with Estimator. In other scenarios it is handled automatically. Returns Output tensor for the block. Note that from stage 3, the first conv layer at main path is with strides=(2, 2) And the shortcut should have strides=(2, 2) as well","title":"medicalai.chief.nnets.resnet.conv_building_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetidentity_building_blockinput_tensor-kernel_size-filters-stage-block-trainingnone","text":"The identity block is the block that has no conv layer at shortcut. Parameters input_tensor \u2013 input tensor kernel_size \u2013 default 3, the kernel size of middle conv layer at main path filters \u2013 list of integers, the filters of 3 conv layer at main path stage \u2013 integer, current stage label, used for generating layer names block \u2013 current block label, used for generating layer names training \u2013 Only used if training keras model with Estimator. In other scenarios it is handled automatically. Returns Output tensor for the block.","title":"medicalai.chief.nnets.resnet.identity_building_block(input_tensor, kernel_size, filters, stage, block, training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnetnum_blocks-img_inputnone-classes10-trainingnone","text":"Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance.","title":"medicalai.chief.nnets.resnet.resnet(num_blocks, img_input=None, classes=10, training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet110-num_blocks110-img_inputnone-classes10-trainingnone","text":"Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance.","title":"medicalai.chief.nnets.resnet.resnet110(*, num_blocks=110, img_input=None, classes=10, training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet20-num_blocks3-img_inputnone-classes10-trainingnone","text":"Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance.","title":"medicalai.chief.nnets.resnet.resnet20(*, num_blocks=3, img_input=None, classes=10, training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet32-num_blocks5-img_inputnone-classes10-trainingnone","text":"Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance.","title":"medicalai.chief.nnets.resnet.resnet32(*, num_blocks=5, img_input=None, classes=10, training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet56-num_blocks9-img_inputnone-classes10-trainingnone","text":"Instantiates the ResNet architecture. Parameters num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2) classes \u2013 optional number of classes to classify images into training \u2013 Only used if training keras model with Estimator. In other it is handled automatically. ( scenarios ) \u2013 Returns A Keras model instance.","title":"medicalai.chief.nnets.resnet.resnet56(*, num_blocks=9, img_input=None, classes=10, training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet_blockinput_tensor-size-kernel_size-filters-stage-conv_strides2-2-trainingnone","text":"A block which applies conv followed by multiple identity blocks. Parameters input_tensor \u2013 input tensor size \u2013 integer, number of constituent conv/identity building blocks. conv block is applied once** , ****followed by** ( A ) \u2013 kernel_size \u2013 default 3, the kernel size of middle conv layer at main path filters \u2013 list of integers, the filters of 3 conv layer at main path stage \u2013 integer, current stage label, used for generating layer names conv_strides \u2013 Strides for the first conv layer in the block. training \u2013 Only used if training keras model with Estimator. In other scenarios it is handled automatically. Returns Output tensor after applying conv and identity blocks.","title":"medicalai.chief.nnets.resnet.resnet_block(input_tensor, size, kernel_size, filters, stage, conv_strides=(2, 2), training=None)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsvgg16-module","text":"","title":"medicalai.chief.nnets.vgg16 module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsvgg16vgg16_modelimg_input224-224-3-classes3","text":"Loaded the VGG16 network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.vgg16.VGG16_Model(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsxception-module","text":"","title":"medicalai.chief.nnets.xception module"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsxceptionxceptionimg_input224-224-3-classes3","text":"Loaded the Xception network, ensuring the head FC layer sets are left off Parameters img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. classes \u2013 Number of classes to be predicted. Returns \u2013 model","title":"medicalai.chief.nnets.xception.Xception(img_input=(224, 224, 3), classes=3)"},{"location":"medicalai/medicalai.chief.nnets/#module-contents","text":"","title":"Module contents"},{"location":"medicalai/medicalai.chief.xai/","text":"medicalai.chief.xai package \u00b6 Submodules \u00b6 medicalai.chief.xai.xcams module \u00b6 medicalai.chief.xai.xcams.predict_with_gradcam(model, imgNP, labels, selected_labels, layer_name='bn', expected=None, predictions=None, showPlot=False) \u00b6 TODO: Explainer requires model to sent for every call. This may be expensive. Need to find a way to Initialize the model or share with predict engine. Else the memory required may double. Module contents \u00b6","title":"medicalai.chief.xai package"},{"location":"medicalai/medicalai.chief.xai/#medicalaichiefxai-package","text":"","title":"medicalai.chief.xai package"},{"location":"medicalai/medicalai.chief.xai/#submodules","text":"","title":"Submodules"},{"location":"medicalai/medicalai.chief.xai/#medicalaichiefxaixcams-module","text":"","title":"medicalai.chief.xai.xcams module"},{"location":"medicalai/medicalai.chief.xai/#medicalaichiefxaixcamspredict_with_gradcammodel-imgnp-labels-selected_labels-layer_namebn-expectednone-predictionsnone-showplotfalse","text":"TODO: Explainer requires model to sent for every call. This may be expensive. Need to find a way to Initialize the model or share with predict engine. Else the memory required may double.","title":"medicalai.chief.xai.xcams.predict_with_gradcam(model, imgNP, labels, selected_labels, layer_name='bn', expected=None, predictions=None, showPlot=False)"},{"location":"medicalai/medicalai.chief.xai/#module-contents","text":"","title":"Module contents"},{"location":"medicalai/medicalai/","text":"medicalai package \u00b6 Subpackages \u00b6 medicalai.chief package Subpackages medicalai.chief.model_metrics package Submodules medicalai.chief.model_metrics.modelstats module Module contents medicalai.chief.nnets package Submodules medicalai.chief.nnets.covid_net module medicalai.chief.nnets.densenet module medicalai.chief.nnets.inceptionResnet module medicalai.chief.nnets.inceptionv3 module medicalai.chief.nnets.mobilenet module medicalai.chief.nnets.mobilenetv2 module medicalai.chief.nnets.resnet module medicalai.chief.nnets.vgg16 module medicalai.chief.nnets.xception module Module contents medicalai.chief.xai package Submodules medicalai.chief.xai.xcams module Module contents Submodules medicalai.chief.core module medicalai.chief.dataset_prepare module medicalai.chief.download_utils module medicalai.chief.networks module medicalai.chief.prettyloss module medicalai.chief.uFuncs module Module contents Module contents \u00b6","title":"medicalai package"},{"location":"medicalai/medicalai/#medicalai-package","text":"","title":"medicalai package"},{"location":"medicalai/medicalai/#subpackages","text":"medicalai.chief package Subpackages medicalai.chief.model_metrics package Submodules medicalai.chief.model_metrics.modelstats module Module contents medicalai.chief.nnets package Submodules medicalai.chief.nnets.covid_net module medicalai.chief.nnets.densenet module medicalai.chief.nnets.inceptionResnet module medicalai.chief.nnets.inceptionv3 module medicalai.chief.nnets.mobilenet module medicalai.chief.nnets.mobilenetv2 module medicalai.chief.nnets.resnet module medicalai.chief.nnets.vgg16 module medicalai.chief.nnets.xception module Module contents medicalai.chief.xai package Submodules medicalai.chief.xai.xcams module Module contents Submodules medicalai.chief.core module medicalai.chief.dataset_prepare module medicalai.chief.download_utils module medicalai.chief.networks module medicalai.chief.prettyloss module medicalai.chief.uFuncs module Module contents","title":"Subpackages"},{"location":"medicalai/medicalai/#module-contents","text":"","title":"Module contents"},{"location":"medicalai/modelStats/","text":"medicalai.chief.model_metrics.modelstats \u00b6 true_positives \u00b6 true_positives ( expected , preds , threshold = 0.5 ) Count true positives. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: true_pos (int): true positives true_negatives \u00b6 true_negatives ( expected , preds , threshold = 0.5 ) Count true negatives. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: true_neg (int): true negatives false_positives \u00b6 false_positives ( expected , preds , threshold = 0.5 ) Count false positives. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: false_pos (int): false positives false_negatives \u00b6 false_negatives ( expected , preds , threshold = 0.5 ) Count false positives. Args: expected (np.array): ground truth, size (n_examples) pred (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: false_neg (int): false negatives get_accuracy \u00b6 get_accuracy ( expected , preds , threshold = 0.9 ) Compute accuracy of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: accuracy (float): accuracy of predictions at threshold get_prevalence \u00b6 get_prevalence ( expected ) Compute accuracy of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) Returns: prevalence (float): prevalence of positive cases get_sensitivity \u00b6 get_sensitivity ( expected , preds , threshold = 0.5 ) Compute sensitivity of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: sensitivity (float): probability that our test outputs positive given that the case is actually positive get_specificity \u00b6 get_specificity ( expected , preds , threshold = 0.5 ) Compute specificity of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: specificity (float): probability that the test outputs negative given that the case is actually negative get_ppv \u00b6 get_ppv ( expected , preds , threshold = 0.5 ) Compute PPV of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: PPV (float): positive predictive value of predictions at threshold get_npv \u00b6 get_npv ( expected , preds , threshold = 0.5 ) Compute NPV of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: NPV (float): negative predictive value of predictions at threshold compute_class_freqs \u00b6 compute_class_freqs ( labels ) Compute positive and negative frequences for each class. Args: labels (np.array): matrix of labels, size (num_examples, num_classes) Returns: positive_frequencies (np.array): array of positive frequences for each class, size (num_classes) negative_frequencies (np.array): array of negative frequences for each class, size (num_classes) get_weighted_loss \u00b6 get_weighted_loss ( pos_weights , neg_weights , epsilon = 1e-07 ) Return weighted loss function given negative weights and positive weights. Args: pos_weights (np.array): array of positive weights for each class, size (num_classes) neg_weights (np.array): array of negative weights for each class, size (num_classes) Returns: weighted_loss (function): weighted loss function generate_evaluation_report \u00b6 generate_evaluation_report ( CLASS_NAMES , predictions , groundTruth = None , generator = None , returnPlot = True , showPlot = True , printStat = True , ** kwargs ) Generates Evaluation PDF Report for a Test/Validation experimentation. Ground truth needs to be passed to generate the pdf report. Args: CLASS_NAMES (list): List of Label names or class names of dataset. predictions (np.array): Predicted output of test data. groundTruth (np.array): Ground truth of test data. generator (Optional): If generator method used in training, pass the generator. returnPlot (Bool): Returns the plot handle if set to `True` showPlot (Bool): Display the plot if set to `True`. [IMP: Until the plot is closed, the code execution is blocked.] printStat (Bool): Print the statistics of the experiment on the console if set to `True`. T **kwargs (Optional): Plot Setting Arguments Returns: true_pos (int): true positives","title":"Model Statistics"},{"location":"medicalai/modelStats/#medicalaichiefmodel_metricsmodelstats","text":"","title":"medicalai.chief.model_metrics.modelstats"},{"location":"medicalai/modelStats/#true_positives","text":"true_positives ( expected , preds , threshold = 0.5 ) Count true positives. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: true_pos (int): true positives","title":"true_positives"},{"location":"medicalai/modelStats/#true_negatives","text":"true_negatives ( expected , preds , threshold = 0.5 ) Count true negatives. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: true_neg (int): true negatives","title":"true_negatives"},{"location":"medicalai/modelStats/#false_positives","text":"false_positives ( expected , preds , threshold = 0.5 ) Count false positives. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: false_pos (int): false positives","title":"false_positives"},{"location":"medicalai/modelStats/#false_negatives","text":"false_negatives ( expected , preds , threshold = 0.5 ) Count false positives. Args: expected (np.array): ground truth, size (n_examples) pred (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: false_neg (int): false negatives","title":"false_negatives"},{"location":"medicalai/modelStats/#get_accuracy","text":"get_accuracy ( expected , preds , threshold = 0.9 ) Compute accuracy of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: accuracy (float): accuracy of predictions at threshold","title":"get_accuracy"},{"location":"medicalai/modelStats/#get_prevalence","text":"get_prevalence ( expected ) Compute accuracy of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) Returns: prevalence (float): prevalence of positive cases","title":"get_prevalence"},{"location":"medicalai/modelStats/#get_sensitivity","text":"get_sensitivity ( expected , preds , threshold = 0.5 ) Compute sensitivity of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: sensitivity (float): probability that our test outputs positive given that the case is actually positive","title":"get_sensitivity"},{"location":"medicalai/modelStats/#get_specificity","text":"get_specificity ( expected , preds , threshold = 0.5 ) Compute specificity of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: specificity (float): probability that the test outputs negative given that the case is actually negative","title":"get_specificity"},{"location":"medicalai/modelStats/#get_ppv","text":"get_ppv ( expected , preds , threshold = 0.5 ) Compute PPV of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: PPV (float): positive predictive value of predictions at threshold","title":"get_ppv"},{"location":"medicalai/modelStats/#get_npv","text":"get_npv ( expected , preds , threshold = 0.5 ) Compute NPV of predictions at threshold. Args: expected (np.array): ground truth, size (n_examples) preds (np.array): model output, size (n_examples) threshold (float): cutoff value for positive prediction from model Returns: NPV (float): negative predictive value of predictions at threshold","title":"get_npv"},{"location":"medicalai/modelStats/#compute_class_freqs","text":"compute_class_freqs ( labels ) Compute positive and negative frequences for each class. Args: labels (np.array): matrix of labels, size (num_examples, num_classes) Returns: positive_frequencies (np.array): array of positive frequences for each class, size (num_classes) negative_frequencies (np.array): array of negative frequences for each class, size (num_classes)","title":"compute_class_freqs"},{"location":"medicalai/modelStats/#get_weighted_loss","text":"get_weighted_loss ( pos_weights , neg_weights , epsilon = 1e-07 ) Return weighted loss function given negative weights and positive weights. Args: pos_weights (np.array): array of positive weights for each class, size (num_classes) neg_weights (np.array): array of negative weights for each class, size (num_classes) Returns: weighted_loss (function): weighted loss function","title":"get_weighted_loss"},{"location":"medicalai/modelStats/#generate_evaluation_report","text":"generate_evaluation_report ( CLASS_NAMES , predictions , groundTruth = None , generator = None , returnPlot = True , showPlot = True , printStat = True , ** kwargs ) Generates Evaluation PDF Report for a Test/Validation experimentation. Ground truth needs to be passed to generate the pdf report. Args: CLASS_NAMES (list): List of Label names or class names of dataset. predictions (np.array): Predicted output of test data. groundTruth (np.array): Ground truth of test data. generator (Optional): If generator method used in training, pass the generator. returnPlot (Bool): Returns the plot handle if set to `True` showPlot (Bool): Display the plot if set to `True`. [IMP: Until the plot is closed, the code execution is blocked.] printStat (Bool): Print the statistics of the experiment on the console if set to `True`. T **kwargs (Optional): Plot Setting Arguments Returns: true_pos (int): true positives","title":"generate_evaluation_report"},{"location":"medicalai/modules/","text":"medicalai \u00b6 medicalai package Subpackages medicalai.chief package Subpackages Submodules medicalai.chief.core module medicalai.chief.dataset_prepare module medicalai.chief.download_utils module medicalai.chief.networks module medicalai.chief.prettyloss module medicalai.chief.uFuncs module Module contents Module contents","title":"medicalai"},{"location":"medicalai/modules/#medicalai","text":"medicalai package Subpackages medicalai.chief package Subpackages Submodules medicalai.chief.core module medicalai.chief.dataset_prepare module medicalai.chief.download_utils module medicalai.chief.networks module medicalai.chief.prettyloss module medicalai.chief.uFuncs module Module contents Module contents","title":"medicalai"},{"location":"medicalai/networks/","text":"medicalai.chief.networks \u00b6 NetworkInit \u00b6 NetworkInit () Base class for parameter Network initializers. The :class: NetworkInit class represents a network initializer used to initialize network/model parameters for numerous medical ai networks. It should be subclassed when implementing new types of network initializers. call \u00b6 NetworkInit . call ( inputSize , OutputSize , convLayers = None ) Sample should return model initialized with input and output Sizes. Parameters \u00b6 inputSize : tuple or int. Integer or tuple specifying the input of network. OutputSize : tuple or int. Integer or tuple specifying the output classes of network. Returns \u00b6 numpy.array. Initialized Model. tinyMedNet \u00b6 tinyMedNet () tinyMedNet is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library. tinyMedNet_v2 \u00b6 tinyMedNet_v2 () tinyMedNet_v2 allows users to configure the number of Conv/CNN layers. tinyMedNet_v2 is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library. tinyMedNet_v3 \u00b6 tinyMedNet_v3 () tinyMedNet_v3 has 3 FC layers with Dropout and Configurable number of Conv/CNN Layers. resNet20 \u00b6 resNet20 () resnet20 resNet32 \u00b6 resNet32 () resnet32 resNet56 \u00b6 resNet56 () RESNET56 resNet110 \u00b6 resNet110 () resnet110 megaNet \u00b6 megaNet () megaNet is based on COVID-NET. This is a tensorflow 2.0 network variant for COVID-Net described in Paper \"COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\" by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/ DenseNet121 \u00b6 DenseNet121 () DenseNet121 model, with weights pre-trained on ImageNet inputSize: input image size tuple outputSize: Number of classes for prediction VGG16 \u00b6 VGG16 () VGG16 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction MobileNet \u00b6 MobileNet () MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction MobileNetV2 \u00b6 MobileNetV2 () MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction Xception \u00b6 Xception () Xception model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction InceptionV3 \u00b6 InceptionV3 () InceptionV3 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction InceptionResNetV2 \u00b6 InceptionResNetV2 () InceptionResNetV2 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"AI Networks"},{"location":"medicalai/networks/#medicalaichiefnetworks","text":"","title":"medicalai.chief.networks"},{"location":"medicalai/networks/#networkinit","text":"NetworkInit () Base class for parameter Network initializers. The :class: NetworkInit class represents a network initializer used to initialize network/model parameters for numerous medical ai networks. It should be subclassed when implementing new types of network initializers.","title":"NetworkInit"},{"location":"medicalai/networks/#call","text":"NetworkInit . call ( inputSize , OutputSize , convLayers = None ) Sample should return model initialized with input and output Sizes.","title":"call"},{"location":"medicalai/networks/#parameters","text":"inputSize : tuple or int. Integer or tuple specifying the input of network. OutputSize : tuple or int. Integer or tuple specifying the output classes of network.","title":"Parameters"},{"location":"medicalai/networks/#returns","text":"numpy.array. Initialized Model.","title":"Returns"},{"location":"medicalai/networks/#tinymednet","text":"tinyMedNet () tinyMedNet is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.","title":"tinyMedNet"},{"location":"medicalai/networks/#tinymednet_v2","text":"tinyMedNet_v2 () tinyMedNet_v2 allows users to configure the number of Conv/CNN layers. tinyMedNet_v2 is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.","title":"tinyMedNet_v2"},{"location":"medicalai/networks/#tinymednet_v3","text":"tinyMedNet_v3 () tinyMedNet_v3 has 3 FC layers with Dropout and Configurable number of Conv/CNN Layers.","title":"tinyMedNet_v3"},{"location":"medicalai/networks/#resnet20","text":"resNet20 () resnet20","title":"resNet20"},{"location":"medicalai/networks/#resnet32","text":"resNet32 () resnet32","title":"resNet32"},{"location":"medicalai/networks/#resnet56","text":"resNet56 () RESNET56","title":"resNet56"},{"location":"medicalai/networks/#resnet110","text":"resNet110 () resnet110","title":"resNet110"},{"location":"medicalai/networks/#meganet","text":"megaNet () megaNet is based on COVID-NET. This is a tensorflow 2.0 network variant for COVID-Net described in Paper \"COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\" by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/","title":"megaNet"},{"location":"medicalai/networks/#densenet121","text":"DenseNet121 () DenseNet121 model, with weights pre-trained on ImageNet inputSize: input image size tuple outputSize: Number of classes for prediction","title":"DenseNet121"},{"location":"medicalai/networks/#vgg16","text":"VGG16 () VGG16 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"VGG16"},{"location":"medicalai/networks/#mobilenet","text":"MobileNet () MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"MobileNet"},{"location":"medicalai/networks/#mobilenetv2","text":"MobileNetV2 () MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"MobileNetV2"},{"location":"medicalai/networks/#xception","text":"Xception () Xception model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"Xception"},{"location":"medicalai/networks/#inceptionv3","text":"InceptionV3 () InceptionV3 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"InceptionV3"},{"location":"medicalai/networks/#inceptionresnetv2","text":"InceptionResNetV2 () InceptionResNetV2 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction","title":"InceptionResNetV2"},{"location":"medicalai/examples/train_using_generator_dataset/","text":"Example 1: Train your model using medicalai generator \u00b6 import os import medicalai as ai import tensorflow as tf Define the hyperparameters \u00b6 Specify the dataset folder which further contains test & train folders each with n class object folders datasetFolderPath = \"../data\" Specify the dimensions of image to be fed to network IMG_HEIGHT = 224 IMG_WIDTH = 224 Specify the number of classes for classification OUTPUT_CLASSES = 3 Specify the name of the model to be trained on EXPT_NAME = '1' AI_NAME = 'mobilenet' MODEL_SAVE_NAME = '../model/' + AI_NAME + '/Medical_RSNA_' + str ( IMG_HEIGHT ) + 'x' + str ( IMG_WIDTH ) + '_' + AI_NAME + '_EXPT_' + str ( EXPT_NAME ) Specify remaining hyperparamters batch_size = 32 epochs = 10 learning_rate = 0.0001 Define the augmentation for the generator \u00b6 augment = ai . AUGMENTATION ( rotation_range = 12 , fill_mode = 'nearest' , width_shift_range = 0.1 , height_shift_range = 0.1 , brightness_range = ( 0.9 , 1.1 ), zoom_range = ( 0.85 , 1.15 ), rescale = 1. / 255 ,) - Load your data from folder using datasetGenFromFolder if your data is in folder structured form dsHandler = ai . datasetGenFromFolder ( folder = datasetFolderPath , targetDim = ( IMG_HEIGHT , IMG_WIDTH ), augmentation = augment , class_mode = \"categorical\" normalize = False , batch_size = batch_size , augmentation = True , color_mode = 'rgb' , #if the images are of rgb channels else 'grayscale' class_mode = 'categorical' , shuffle = True , seed = 23 )) trainGen , testGen = dsHandler . load_generator () - Incase your data is not in folder structured form but rather details embeded in a csv file, use the datasetGenFromDataframe method to load data to generator instead of datasetGenFromFolder dsHandler = ai . datasetGenFromDataframe ( folder = datasetFolderPath , #folder containg train and test folders csv_path = '.' , #path to train.cvs and test.csv x_col = 'name' , y_col = 'labels' , targetDim = ( IMG_HEIGHT , IMG_WIDTH ), normalize = False , batch_size = batch_size , augmentation = True , color_mode = 'rgb' , class_mode = 'sparse' , shuffle = True , seed = 23 ) trainGen , testGen = dsHandler . load_generator () Train model \u00b6 Now our image generator is ready to be trained on our model. But first we need to define a tensorflow callback for the model model_checkpoint = tf . keras . callbacks . ModelCheckpoint ( MODEL_SAVE_NAME + 'best.h5' , verbose = 0 , mode = 'auto' , save_freq = 5 , save_best_only = True , ) callbacks = [ model_checkpoint ] trainer = ai . TRAIN_ENGINE () trainer . train_and_save_model ( AI_NAME = AI_NAME , MODEL_SAVE_NAME = MODEL_SAVE_NAME , trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , RETRAIN_MODEL = True , BATCH_SIZE = batch_size , EPOCHS = epochs , LEARNING_RATE = learning_rate , SAVE_BEST_MODEL = True , callbacks = callbacks , convLayers = None , loss = 'categorical_crossentropy' , showModel = False #mark this True if you want to see model summary ) - Use the above model to predict test_x , test_y = dsHandler . get_numpy ( testGen ) predsG = trainer . predict ( test_x ) - Generate evaluation report trainer . generate_evaluation_report ( testGen , predictions = predsG )","title":"Train Using Generator Method"},{"location":"medicalai/examples/train_using_generator_dataset/#example-1-train-your-model-using-medicalai-generator","text":"import os import medicalai as ai import tensorflow as tf","title":"Example 1: Train your model using medicalai generator"},{"location":"medicalai/examples/train_using_generator_dataset/#define-the-hyperparameters","text":"Specify the dataset folder which further contains test & train folders each with n class object folders datasetFolderPath = \"../data\" Specify the dimensions of image to be fed to network IMG_HEIGHT = 224 IMG_WIDTH = 224 Specify the number of classes for classification OUTPUT_CLASSES = 3 Specify the name of the model to be trained on EXPT_NAME = '1' AI_NAME = 'mobilenet' MODEL_SAVE_NAME = '../model/' + AI_NAME + '/Medical_RSNA_' + str ( IMG_HEIGHT ) + 'x' + str ( IMG_WIDTH ) + '_' + AI_NAME + '_EXPT_' + str ( EXPT_NAME ) Specify remaining hyperparamters batch_size = 32 epochs = 10 learning_rate = 0.0001","title":"Define the hyperparameters"},{"location":"medicalai/examples/train_using_generator_dataset/#define-the-augmentation-for-the-generator","text":"augment = ai . AUGMENTATION ( rotation_range = 12 , fill_mode = 'nearest' , width_shift_range = 0.1 , height_shift_range = 0.1 , brightness_range = ( 0.9 , 1.1 ), zoom_range = ( 0.85 , 1.15 ), rescale = 1. / 255 ,) - Load your data from folder using datasetGenFromFolder if your data is in folder structured form dsHandler = ai . datasetGenFromFolder ( folder = datasetFolderPath , targetDim = ( IMG_HEIGHT , IMG_WIDTH ), augmentation = augment , class_mode = \"categorical\" normalize = False , batch_size = batch_size , augmentation = True , color_mode = 'rgb' , #if the images are of rgb channels else 'grayscale' class_mode = 'categorical' , shuffle = True , seed = 23 )) trainGen , testGen = dsHandler . load_generator () - Incase your data is not in folder structured form but rather details embeded in a csv file, use the datasetGenFromDataframe method to load data to generator instead of datasetGenFromFolder dsHandler = ai . datasetGenFromDataframe ( folder = datasetFolderPath , #folder containg train and test folders csv_path = '.' , #path to train.cvs and test.csv x_col = 'name' , y_col = 'labels' , targetDim = ( IMG_HEIGHT , IMG_WIDTH ), normalize = False , batch_size = batch_size , augmentation = True , color_mode = 'rgb' , class_mode = 'sparse' , shuffle = True , seed = 23 ) trainGen , testGen = dsHandler . load_generator ()","title":"Define the augmentation for the generator"},{"location":"medicalai/examples/train_using_generator_dataset/#train-model","text":"Now our image generator is ready to be trained on our model. But first we need to define a tensorflow callback for the model model_checkpoint = tf . keras . callbacks . ModelCheckpoint ( MODEL_SAVE_NAME + 'best.h5' , verbose = 0 , mode = 'auto' , save_freq = 5 , save_best_only = True , ) callbacks = [ model_checkpoint ] trainer = ai . TRAIN_ENGINE () trainer . train_and_save_model ( AI_NAME = AI_NAME , MODEL_SAVE_NAME = MODEL_SAVE_NAME , trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , RETRAIN_MODEL = True , BATCH_SIZE = batch_size , EPOCHS = epochs , LEARNING_RATE = learning_rate , SAVE_BEST_MODEL = True , callbacks = callbacks , convLayers = None , loss = 'categorical_crossentropy' , showModel = False #mark this True if you want to see model summary ) - Use the above model to predict test_x , test_y = dsHandler . get_numpy ( testGen ) predsG = trainer . predict ( test_x ) - Generate evaluation report trainer . generate_evaluation_report ( testGen , predictions = predsG )","title":"Train model"},{"location":"medicalai/examples/train_using_numpy_dataset/","text":"Example 1: IMAGE Recognition/Classification \u00b6 Train an AI model using medicalai's numpy dataset processor \u00b6 import os import medicalai as ai Download sample Dataset \u00b6 datasetDWLD = ai . getFile ( 'https://github.com/aibharata/covid19-dataset/archive/v1.0.zip' , subDir = 'dataset' ) datasetFolderPath = datasetDWLD + '/covid19-dataset-1.0/chest-xray-pnumonia-covid19/' Define the hyperparameters of Dataset Processor \u00b6 A. Specify the dimensions of image to be fed to network IMG_HEIGHT = 64 IMG_WIDTH = 64 OUTPUT_CLASSES = 3 Process your dataset using Numpy based datasetFromFolder class. \u00b6 The datasetFromFolder class takes a folder path where your dataset is located. This folder should have test and train folders. Each of the folder should have the class sub-folder for your classification problem. trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( IMG_WIDTH , IMG_WIDTH )) . load_dataset () # Print shapes of the loaded test and train data print ( 'TrainSet Data Shape: {:} ; TrainSet Labels Shape: {:} ' . format ( testSet . data . shape , testSet . labels . shape )) print ( 'TrainSet Data Shape: {:} ; TrainSet Labels Shape: {:} ' . format ( testSet . data . shape , testSet . labels . shape )) Define the hyperparameters of Training \u00b6 A. Specify training hyperparamters batch_size = 32 epochs = 10 learning_rate = 0.0001 B. Specify the model name to save/retrain MODEL_SAVE_NAME = 'medicalai_test_model_1' C. Choose from the prebuilt networks from Medicalai Library. You can also pass a class with your own custom network to AI_NAME parameter. AI_NAME = 'tinyMedNet' Initialize TRAIN_ENGINE and Start Training \u00b6 trainer = ai . TRAIN_ENGINE () trainer . train_and_save_model ( AI_NAME = AI_NAME , MODEL_SAVE_NAME = MODEL_SAVE_NAME , trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , RETRAIN_MODEL = True , BATCH_SIZE = batch_size , EPOCHS = epochs , LEARNING_RATE = learning_rate , SAVE_BEST_MODEL = True , showModel = True # Set this True if you want to see model summary ) View and Save Training Stats \u00b6 Plot training accuracy and loss w.r.t to epochs trainer . plot_train_acc_loss () Generate evaluation report for Trained Model \u00b6 trainer . generate_evaluation_report ( testSet ) Explain the model for a input sample \u00b6 trainer . explain ( testSet . data [ 0 : 1 ], layer_to_explain = 'CNN3' , classNames = labelNames )","title":"Train Using Numpy Method"},{"location":"medicalai/examples/train_using_numpy_dataset/#example-1-image-recognitionclassification","text":"","title":"Example 1: IMAGE Recognition/Classification"},{"location":"medicalai/examples/train_using_numpy_dataset/#train-an-ai-model-using-medicalais-numpy-dataset-processor","text":"import os import medicalai as ai","title":"Train an AI model using medicalai's numpy dataset processor"},{"location":"medicalai/examples/train_using_numpy_dataset/#download-sample-dataset","text":"datasetDWLD = ai . getFile ( 'https://github.com/aibharata/covid19-dataset/archive/v1.0.zip' , subDir = 'dataset' ) datasetFolderPath = datasetDWLD + '/covid19-dataset-1.0/chest-xray-pnumonia-covid19/'","title":"Download sample Dataset"},{"location":"medicalai/examples/train_using_numpy_dataset/#define-the-hyperparameters-of-dataset-processor","text":"A. Specify the dimensions of image to be fed to network IMG_HEIGHT = 64 IMG_WIDTH = 64 OUTPUT_CLASSES = 3","title":"Define the hyperparameters of Dataset Processor"},{"location":"medicalai/examples/train_using_numpy_dataset/#process-your-dataset-using-numpy-based-datasetfromfolder-class","text":"The datasetFromFolder class takes a folder path where your dataset is located. This folder should have test and train folders. Each of the folder should have the class sub-folder for your classification problem. trainSet , testSet , labelNames = ai . datasetFromFolder ( datasetFolderPath , targetDim = ( IMG_WIDTH , IMG_WIDTH )) . load_dataset () # Print shapes of the loaded test and train data print ( 'TrainSet Data Shape: {:} ; TrainSet Labels Shape: {:} ' . format ( testSet . data . shape , testSet . labels . shape )) print ( 'TrainSet Data Shape: {:} ; TrainSet Labels Shape: {:} ' . format ( testSet . data . shape , testSet . labels . shape ))","title":"Process your dataset using Numpy based datasetFromFolder class."},{"location":"medicalai/examples/train_using_numpy_dataset/#define-the-hyperparameters-of-training","text":"A. Specify training hyperparamters batch_size = 32 epochs = 10 learning_rate = 0.0001 B. Specify the model name to save/retrain MODEL_SAVE_NAME = 'medicalai_test_model_1' C. Choose from the prebuilt networks from Medicalai Library. You can also pass a class with your own custom network to AI_NAME parameter. AI_NAME = 'tinyMedNet'","title":"Define the hyperparameters of Training"},{"location":"medicalai/examples/train_using_numpy_dataset/#initialize-train_engine-and-start-training","text":"trainer = ai . TRAIN_ENGINE () trainer . train_and_save_model ( AI_NAME = AI_NAME , MODEL_SAVE_NAME = MODEL_SAVE_NAME , trainSet = trainGen , testSet = testGen , OUTPUT_CLASSES = OUTPUT_CLASSES , RETRAIN_MODEL = True , BATCH_SIZE = batch_size , EPOCHS = epochs , LEARNING_RATE = learning_rate , SAVE_BEST_MODEL = True , showModel = True # Set this True if you want to see model summary )","title":"Initialize TRAIN_ENGINE and Start Training"},{"location":"medicalai/examples/train_using_numpy_dataset/#view-and-save-training-stats","text":"Plot training accuracy and loss w.r.t to epochs trainer . plot_train_acc_loss ()","title":"View and Save Training Stats"},{"location":"medicalai/examples/train_using_numpy_dataset/#generate-evaluation-report-for-trained-model","text":"trainer . generate_evaluation_report ( testSet )","title":"Generate evaluation report for Trained Model"},{"location":"medicalai/examples/train_using_numpy_dataset/#explain-the-model-for-a-input-sample","text":"trainer . explain ( testSet . data [ 0 : 1 ], layer_to_explain = 'CNN3' , classNames = labelNames )","title":"Explain the model for a input sample"}]}